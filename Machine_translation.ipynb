{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_translation.ipynb",
      "provenance": [],
      "mount_file_id": "1-4K2HI3_RBvxi7ln2M30dSS8qpHvCFTH",
      "authorship_tag": "ABX9TyNXTTNINPIa1WulYTWI6WL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kushagra2000/Neural_machine_translation/blob/main/Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "a_wTnIFR8vNu",
        "outputId": "2a5a18ce-5479-4c81-a1b1-c8677252a2c2"
      },
      "source": [
        "#imports\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Activation,InputLayer,Embedding\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eacpqiV9DTc"
      },
      "source": [
        "#Upload the deu.txt file and put it in the Data Folder\n",
        "#!ls Data/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjnci4B5Aywh"
      },
      "source": [
        "#reading lines from the txt file\n",
        "with open('drive/MyDrive/deu.txt','r',encoding='utf-8') as f:\n",
        "  lines=(f.readlines())\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDt6gkPfKhs"
      },
      "source": [
        "#Hyperparameters go here\n",
        "num_examples=15000\n",
        "test_size=0.3\n",
        "m1_lr=0.001\n",
        "m2_lr=0.005\n",
        "m1_lstm_units=64\n",
        "m2_lstm_units=64\n",
        "m1_epochs=25\n",
        "m2_epochs=30\n",
        "m1_batch_size=128\n",
        "m2_batch_size=128\n",
        "m2_embedding_col=64"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSnn6gGCBEy5"
      },
      "source": [
        "#removing the unnecessary data and obtaining sentence pairs \n",
        "def process_text(lines,translate_mode):\n",
        "  ''' \n",
        "  Takes a list of tab seperated\n",
        "  English and German sentences as input \n",
        "  and returns dataframe of processed\n",
        "  English and German sentence pairs\n",
        "  '''\n",
        "  proc_lines=[]\n",
        "  if translate_mode==False:\n",
        "    for line in lines:\n",
        "      line=line.strip() #to remove newlines at the end of a sentence\n",
        "      line=line.split(\"\\t\") #splitting by tabs\n",
        "      line=line[:-1]  #remove contributing information\n",
        "      \n",
        "      line[0]=''.join(c for c in unicodedata.normalize('NFD', line[0]) if unicodedata.category(c) != 'Mn')\n",
        "      line[0]=line[0].encode('utf8','ignore').decode('utf8')\n",
        "      line[0]=line[0].replace(u'\\u200b',' ')\n",
        "      line[0]=line[0].lower()\n",
        "      line[0]=line[0].replace('\\xa0', ' ')\n",
        "      line[0]=re.sub(r\"([.,?!;])\",r\" \\1 \",line[0])   #adding spaces before and after punctuation\n",
        "      line[0]=re.sub(r\"[0-9]\",\" \",line[0])\n",
        "      line[0]=re.sub(r'[\"]',\" \",line[0])\n",
        "      line[0]=re.sub(r\"[']\",\"\",line[0])\n",
        "      line[0]=re.sub(r\"[%-,]\",\" \",line[0])\n",
        "      line[0]=re.sub(r\"[:]\",\" \",line[0])\n",
        "      line[0]=re.sub(r'[\" \"]+',\" \",line[0])  #removing excess spaces\n",
        "      line[0]=line[0].strip() #removing spaces from the end of string\n",
        "      line[0]=\"<SOS> \"+line[0]+\" <EOS>\"\n",
        "\n",
        "      line[1]=''.join(c for c in unicodedata.normalize('NFD', line[1]) if unicodedata.category(c) != 'Mn')\n",
        "      line[1]=line[1].replace(u'\\u200b',' ')\n",
        "      line[1]=line[1].replace('\\xa0', ' ')\n",
        "      line[1]=line[1].lower()\n",
        "      line[1]=re.sub(r\"([.,?!;])\",r\" \\1 \",line[1])\n",
        "      line[1]=re.sub(r\"[0-9]\",r\" \",line[1])\n",
        "      line[1]=re.sub(r'[\"]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[—]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[„]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[“]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[–]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[‘‚]',\"\",line[1])\n",
        "      line[1]=re.sub(r\"[']\",\"\",line[1])\n",
        "      line[1]=re.sub(r\"[%()-,]\",\" \",line[1])\n",
        "      line[1]=re.sub(r\"[:]\",\" \",line[1])\n",
        "      line[1]=re.sub(r'[\" \"]+',\" \",line[1])\n",
        "      line[1]=line[1].strip()\n",
        "      line[1]=\"<SOS> \"+line[1]+\" <EOS>\"\n",
        "\n",
        "      proc_lines.append(line) \n",
        "    return pd.DataFrame.from_records(data=proc_lines,columns=['eng','ger'])\n",
        "  else:\n",
        "    lines=lines.strip()\n",
        "    lines=''.join(c for c in unicodedata.normalize('NFD', lines) if unicodedata.category(c) != 'Mn')\n",
        "    lines=lines.encode('utf8','ignore').decode('utf8')\n",
        "    lines=lines.replace(u'\\u200b',' ')\n",
        "    lines=lines.lower()\n",
        "    lines=lines.replace('\\xa0', ' ')\n",
        "    lines=re.sub(r\"([.,?!;])\",r\" \\1 \",lines)   #adding spaces before and after punctuation\n",
        "    lines=re.sub(r\"[0-9]\",\" \",lines)\n",
        "    lines=re.sub(r'[\"]',\" \",lines)\n",
        "    lines=re.sub(r\"[']\",\"\",lines)\n",
        "    lines=re.sub(r\"[%-,]\",\" \",lines)\n",
        "    lines=re.sub(r\"[:]\",\" \",lines)\n",
        "    lines=re.sub(r'[\" \"]+',\" \",lines)  #removing excess spaces\n",
        "    lines=lines.strip() #removing spaces from the end of string\n",
        "    lines=\"<SOS> \"+lines+\" <EOS>\"\n",
        "    return lines\n",
        "\n",
        "  \n",
        "     \n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vWgVr4xOBK33",
        "outputId": "b9a7de2a-2be9-4c21-b377-07c8ec426144"
      },
      "source": [
        "#reading in the dataset, sampling randomly, shuffling and removing duplicates \n",
        "df=process_text(lines,False)\n",
        "df=df.sample(n=num_examples, random_state=1)\n",
        "df.drop_duplicates(subset=\"eng\",inplace=True)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;SOS&gt; doesnt tom go to boston every month ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; fahrt tom nicht jeden monat nach boston ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;SOS&gt; the doctor told tom to stay in bed and g...</td>\n",
              "      <td>&lt;SOS&gt; der arzt wies tom an bettruhe einzuhalte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;SOS&gt; whats your favorite hot drink ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; was ist dein liebstes warmes getrank ? &lt;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;SOS&gt; he died of lung cancer . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; er starb an lungenkrebs . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;SOS&gt; hes always scowling . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; er schaut immer bose drein . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;SOS&gt; it would be fun to see how things change...</td>\n",
              "      <td>&lt;SOS&gt; es ware lustig zu sehen wie die dinge si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;SOS&gt; will you lend me your pencil ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; leihst du mir deinen stift ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;SOS&gt; tom sat at the bar with mary . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; tom saß mit mary in der bar . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;SOS&gt; i want you to go to osaka at once . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich will dass sie sofort nach osaka fahr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;SOS&gt; will you let tom leave ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; lasst ihr tom gehen ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 eng                                                ger\n",
              "0  <SOS> doesnt tom go to boston every month ? <EOS>  <SOS> fahrt tom nicht jeden monat nach boston ...\n",
              "1  <SOS> the doctor told tom to stay in bed and g...  <SOS> der arzt wies tom an bettruhe einzuhalte...\n",
              "2        <SOS> whats your favorite hot drink ? <EOS>  <SOS> was ist dein liebstes warmes getrank ? <...\n",
              "3               <SOS> he died of lung cancer . <EOS>              <SOS> er starb an lungenkrebs . <EOS>\n",
              "4                  <SOS> hes always scowling . <EOS>           <SOS> er schaut immer bose drein . <EOS>\n",
              "5  <SOS> it would be fun to see how things change...  <SOS> es ware lustig zu sehen wie die dinge si...\n",
              "6         <SOS> will you lend me your pencil ? <EOS>           <SOS> leihst du mir deinen stift ? <EOS>\n",
              "7         <SOS> tom sat at the bar with mary . <EOS>          <SOS> tom saß mit mary in der bar . <EOS>\n",
              "8    <SOS> i want you to go to osaka at once . <EOS>  <SOS> ich will dass sie sofort nach osaka fahr...\n",
              "9               <SOS> will you let tom leave ? <EOS>                  <SOS> lasst ihr tom gehen ? <EOS>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGB8vaIOfW5r"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "DNmFdtxhtnjz",
        "outputId": "6f72c403-afca-4339-b16b-9415f725f99d"
      },
      "source": [
        "df.tail(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14706</th>\n",
              "      <td>&lt;SOS&gt; tom and mary quarreled . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; tom und maria stritten sich . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14707</th>\n",
              "      <td>&lt;SOS&gt; this doesnt taste like pork to me . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; fur mich schmeckt das nicht nach schwein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14708</th>\n",
              "      <td>&lt;SOS&gt; tom has two brothers . one lives in bost...</td>\n",
              "      <td>&lt;SOS&gt; tom hat zwei bruder . der eine lebt in b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14709</th>\n",
              "      <td>&lt;SOS&gt; the united states is the largest produce...</td>\n",
              "      <td>&lt;SOS&gt; die vereinigten staaten sind der großte ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14710</th>\n",
              "      <td>&lt;SOS&gt; she can sew very well . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; sie kann ziemlich gut nahen . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14711</th>\n",
              "      <td>&lt;SOS&gt; i have a friend whos a vegetarian . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich habe einen freund der vegetarier ist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14712</th>\n",
              "      <td>&lt;SOS&gt; this is a defibrillator . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; das ist ein defibrillator . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14713</th>\n",
              "      <td>&lt;SOS&gt; were sad . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; wir sind traurig . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14714</th>\n",
              "      <td>&lt;SOS&gt; i think i remember you . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich glaube ich erinnere mich an sie . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14715</th>\n",
              "      <td>&lt;SOS&gt; eggs are very fragile . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; eier sind sehr zerbrechlich . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     eng                                                ger\n",
              "14706               <SOS> tom and mary quarreled . <EOS>          <SOS> tom und maria stritten sich . <EOS>\n",
              "14707    <SOS> this doesnt taste like pork to me . <EOS>  <SOS> fur mich schmeckt das nicht nach schwein...\n",
              "14708  <SOS> tom has two brothers . one lives in bost...  <SOS> tom hat zwei bruder . der eine lebt in b...\n",
              "14709  <SOS> the united states is the largest produce...  <SOS> die vereinigten staaten sind der großte ...\n",
              "14710                <SOS> she can sew very well . <EOS>          <SOS> sie kann ziemlich gut nahen . <EOS>\n",
              "14711    <SOS> i have a friend whos a vegetarian . <EOS>  <SOS> ich habe einen freund der vegetarier ist...\n",
              "14712              <SOS> this is a defibrillator . <EOS>            <SOS> das ist ein defibrillator . <EOS>\n",
              "14713                             <SOS> were sad . <EOS>                     <SOS> wir sind traurig . <EOS>\n",
              "14714               <SOS> i think i remember you . <EOS>  <SOS> ich glaube ich erinnere mich an sie . <EOS>\n",
              "14715                <SOS> eggs are very fragile . <EOS>          <SOS> eier sind sehr zerbrechlich . <EOS>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zctawZ8xGF_R"
      },
      "source": [
        "class Vocab_builder():\n",
        "  '''\n",
        "  Builds vocabulary and \n",
        "  word to index and index to word dictionaries\n",
        "  from dataset\n",
        "  '''\n",
        "  def __init__(self,lang,series):\n",
        "    self.lang=lang\n",
        "    self.data=series\n",
        "  def tokenize(self,line):\n",
        "    return line.split(' ')\n",
        "  def build_vocab(self):\n",
        "    self.uniq_words=set()\n",
        "    \n",
        "    self.maxlen=0\n",
        "    count=3\n",
        "    self.num_list=[]\n",
        "    for index,line in self.data.items():\n",
        "      self.word_list=self.tokenize(line)\n",
        "      self.maxlen=max(len(self.word_list),self.maxlen)\n",
        "      for word in self.word_list:\n",
        "        if(word not in self.uniq_words and word!='<EOS>' and word!='<SOS>'):\n",
        "          self.uniq_words.add(word)\n",
        "          self.num_list.append(count)\n",
        "          count+=1\n",
        "      \n",
        "    self.vocab_list=['<PAD>','<SOS>','<EOS>']+sorted(list(self.uniq_words))\n",
        "    self.num_list=[0,1,2]+self.num_list\n",
        "    print(\"Built vocabulary having {} elements\".format(len(self.vocab_list)))\n",
        "    print(\"Largest sentence length (with tags):{}\".format(self.maxlen))\n",
        "    return dict(zip(self.vocab_list,self.num_list)),dict(zip(self.num_list,self.vocab_list))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JVuh6iKohIC"
      },
      "source": [
        "#Objects of Vocab_builder class\n",
        "eng=Vocab_builder('eng',df['eng'])\n",
        "ger=Vocab_builder('ger',df['ger'])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL4ZAsYizIsd",
        "outputId": "18065eca-59f3-47b9-c13d-4fd548938258"
      },
      "source": [
        "#English word to index and index to word dictionaries\n",
        "eng_w2i,eng_i2w=eng.build_vocab()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built vocabulary having 5903 elements\n",
            "Largest sentence length (with tags):31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsH4pLi3zOcS",
        "outputId": "2dfd6964-6d26-44c6-de23-875ee55f0ac3"
      },
      "source": [
        "#checking for special characters in English dictionary\n",
        "for i in sorted (eng_w2i.keys())[:20] :  \n",
        "     print(i, end = \" \") "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! $ -to- . ; <EOS> <PAD> <SOS> ? a abandon abandoned abducted ability able aboard about above abroad absent "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWE4mEkcMF2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea95b1e-4f04-4b9b-bfba-f263b3d7473a"
      },
      "source": [
        "#German word to index and index to word dictionaries\n",
        "ger_w2i,ger_i2w=ger.build_vocab()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built vocabulary having 9004 elements\n",
            "Largest sentence length (with tags):30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDAzP_ePoJK0",
        "outputId": "68495c16-afb0-4172-db45-008a300f488c"
      },
      "source": [
        "#checking if the index dictionaries are correct\n",
        "'geh'==ger_i2w[ger_w2i['geh']]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tylnxt3Xoqj3",
        "outputId": "46503e4d-24d2-4160-c419-2a383a8c49f6"
      },
      "source": [
        "'go'==eng_i2w[eng_w2i['go']]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rglyUxdDxD3Z",
        "outputId": "3f5670c8-7cdc-4282-a74f-b2818703de30"
      },
      "source": [
        "#checking for special characters in German dictionary\n",
        "for i in sorted (ger_w2i.keys())[:20] :  \n",
        "     print(i, end = \" \") "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! $ - . ; <EOS> <PAD> <SOS> ? ab abbekommen abbezahlen abbiegen abbringen abend abendbrot abende abendessen abendkleid abendkleider "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HctDyjqmxKuX"
      },
      "source": [
        "def sent_to_ind(sentence,lang):\n",
        "  '''\n",
        "  Tokenizes a string and\n",
        "  converts it to an np array of \n",
        "  indices and pads the \n",
        "  array according to max sentence length\n",
        "  '''\n",
        "  ind_list=[]\n",
        "  if lang=='eng':\n",
        "    tokens=eng.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      ind_list.append(eng_w2i[token])\n",
        "    while len(ind_list)<max(ger.maxlen,eng.maxlen):\n",
        "      ind_list.append(0)\n",
        "  else:\n",
        "    tokens=ger.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      ind_list.append(ger_w2i[token])\n",
        "    while len(ind_list)<max(ger.maxlen,eng.maxlen):\n",
        "      ind_list.append(0)\n",
        "    \n",
        "  return np.array(ind_list)\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix5EpSK3eQod",
        "outputId": "beb3868f-45bb-450b-f55f-83a11a11ce38"
      },
      "source": [
        "#Checking correctness of sentence to index conversion\n",
        "test_lis=sent_to_ind('<SOS> tom wird bald hier sein . was heißt bald ? <EOS>','ger')\n",
        "\n",
        "print(len(test_lis))\n",
        "print(test_lis)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n",
            "[   1 7289 8594  760 3778 6624    6 8352 3693  760    8    2    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfhMnYBhXb8",
        "outputId": "93a8ec90-7e37-4d23-b421-09613560ac37"
      },
      "source": [
        "test_lis=sent_to_ind(\"<SOS> tom will be here soon . how soon ? <EOS>\",'eng')\n",
        "print(len(test_lis))\n",
        "print(test_lis)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n",
            "[   1 5312 5770  457 2477 4788    6 2570 4788    8    2    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VENEOHriC99"
      },
      "source": [
        "#splitting the data into training,testing and validation sets\n",
        "\n",
        "train_x,test_x,train_y,test_y=train_test_split(df['eng'],df['ger'],test_size=0.1,random_state=42)\n",
        "train_x,val_x,train_y,val_y=train_test_split(train_x,train_y,test_size=0.23,random_state=42)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NetMWl-AtVvi"
      },
      "source": [
        "def sent_to_np(series,lang,translate_mode):\n",
        "  '''\n",
        "  Converts a dataframe column to \n",
        "  a unsqueezed np array of indexes\n",
        "  with padding for feeding into NN\n",
        "  '''\n",
        "  ret_list=[]\n",
        "  if translate_mode==False :\n",
        "    if lang=='eng':\n",
        "      for index,val in series.items():\n",
        "        ret_list.append(sent_to_ind(val,'eng'))\n",
        "    else:\n",
        "      for index,val in series.items():\n",
        "        ret_list.append(sent_to_ind(val,'ger'))\n",
        "    \n",
        "    ret_list=np.array(ret_list)\n",
        "    return np.expand_dims(ret_list,axis=2)\n",
        "  else:\n",
        "    ans=sent_to_ind(series,'eng')\n",
        "    ans=np.expand_dims(ans,axis=0)\n",
        "    ans=np.expand_dims(ans,axis=2)\n",
        "    return ans\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdCHrrTaSqww"
      },
      "source": [
        "train_x=sent_to_np(train_x,'eng',False)\n",
        "train_y=sent_to_np(train_y,'ger',False)\n",
        "test_x=sent_to_np(test_x,'eng',False)\n",
        "test_y=sent_to_np(test_y,'ger',False)\n",
        "val_x=sent_to_np(val_x,'eng',False)\n",
        "val_y=sent_to_np(val_y,'ger',False)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEbhTzocTrYu"
      },
      "source": [
        "#loading training,testing and validation data\n",
        "\n",
        "# train_x=np.load(\"drive/MyDrive/data/training/train_x.npy\")\n",
        "# train_y=np.load(\"drive/MyDrive/data/training/train_y.npy\")\n",
        "\n",
        "# test_x=np.load(\"drive/MyDrive/data/testing/test_x.npy\")\n",
        "# test_y=np.load(\"drive/MyDrive/data/testing/test_y.npy\")\n",
        "\n",
        "# val_x=np.load(\"drive/MyDrive/data/validation/val_x.npy\")\n",
        "# val_y=np.load(\"drive/MyDrive/data/validation/val_y.npy\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDpCjhQZur_O",
        "outputId": "d2b1d6e1-7a85-4c2d-b1e8-9b5fa2ec7b51"
      },
      "source": [
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10197, 31, 1)\n",
            "(10197, 31, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Frd_j1wuxz5",
        "outputId": "251e1d0c-c5e1-49a2-a385-acd331edfa1c"
      },
      "source": [
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1472, 31, 1)\n",
            "(1472, 31, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1dFoeFhuzjt",
        "outputId": "6d4a96e2-f752-475f-816b-1330838db3c5"
      },
      "source": [
        "print(val_x.shape)\n",
        "print(val_y.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3047, 31, 1)\n",
            "(3047, 31, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zt6VKybF7WK"
      },
      "source": [
        "def translate(sentence,mod,embedded):\n",
        "  '''\n",
        "  Function for translating given English sentence\n",
        "  to German using model predictions\n",
        "  '''\n",
        "  ans=[]\n",
        "  preproc_sent=process_text(sentence,True)\n",
        "  #print(preproc_sent)\n",
        "  model_inp=sent_to_np(preproc_sent,'eng',True)\n",
        "  if (embedded):\n",
        "    model_inp=np.squeeze(model_inp,axis=2)\n",
        "  #print(model_inp)\n",
        "  pred=mod.predict(model_inp)\n",
        "  #print(pred)\n",
        "  for i in pred[0]:\n",
        "    ind=np.argmax(i)\n",
        "    #print(ind)\n",
        "    #print(\"MAX:\",i[ind])\n",
        "    #print(i[24])\n",
        "    ans.append(ger_i2w[ind])\n",
        "  return str(ans)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_cqENbVFpVI"
      },
      "source": [
        "#training starts here ----------------------------------------------------------"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEFKmQmibP_y"
      },
      "source": [
        "# def f1_score(y_true,y_pred):\n",
        "#   p=tf.keras.metrics.Precision()\n",
        "#   r=tf.keras.metrics.Recall()\n",
        "#   p.update_state(y_true,y_pred)\n",
        "#   r.update_state(y_true,y_pred)\n",
        "#   return (2*p.result()*r.result())/(p.result()+r.result());\n",
        "\n",
        "\n",
        "def base_LSTM_model(m1_lr,m1_lstm_units):\n",
        "  '''\n",
        "  Simple LSTM model\n",
        "  '''\n",
        "  lstm=LSTM(m1_lstm_units,return_sequences=True,activation='tanh')  #LSTM layer with output being hiddent state at time t\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation='softmax')) #Dense layer acting on hidden output at each step to generate predictions\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(InputLayer(train_x.shape[1:]))\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(m1_lr),metrics=['accuracy','MeanSquaredError'])\n",
        "  return model\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWOrrfsRNOcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b6c959-e41d-42af-ce5c-6198056a5b1c"
      },
      "source": [
        "base_model=base_LSTM_model(m1_lr,m1_lstm_units)\n",
        "base_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzsf600cPN9w",
        "outputId": "0864fc9a-eaaf-4079-b39f-0b9625f3b2ce"
      },
      "source": [
        "#training the base model\n",
        "\n",
        "base_model.fit(train_x,train_y,m1_batch_size,m1_epochs,validation_data=(val_x,val_y))\n",
        "#base_model.save(\"Less_trained_base.h5\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 10197 samples, validate on 3047 samples\n",
            "Epoch 1/25\n",
            "10197/10197 [==============================] - 9s 898us/sample - loss: 5.6665 - acc: 0.6701 - mean_squared_error: 5503041.5000 - val_loss: 2.2605 - val_acc: 0.6959 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 2/25\n",
            "10197/10197 [==============================] - 7s 693us/sample - loss: 2.0554 - acc: 0.7004 - mean_squared_error: 5503041.5000 - val_loss: 1.9712 - val_acc: 0.7031 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 3/25\n",
            "10197/10197 [==============================] - 7s 666us/sample - loss: 1.9074 - acc: 0.7252 - mean_squared_error: 5503041.0000 - val_loss: 1.8987 - val_acc: 0.7372 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 4/25\n",
            "10197/10197 [==============================] - 7s 671us/sample - loss: 1.8552 - acc: 0.7431 - mean_squared_error: 5503041.5000 - val_loss: 1.8662 - val_acc: 0.7402 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 5/25\n",
            "10197/10197 [==============================] - 7s 646us/sample - loss: 1.8223 - acc: 0.7444 - mean_squared_error: 5503042.0000 - val_loss: 1.8353 - val_acc: 0.7452 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 6/25\n",
            "10197/10197 [==============================] - 7s 666us/sample - loss: 1.7803 - acc: 0.7472 - mean_squared_error: 5503042.0000 - val_loss: 1.7899 - val_acc: 0.7447 - val_mean_squared_error: 5536400.0000\n",
            "Epoch 7/25\n",
            "10197/10197 [==============================] - 7s 677us/sample - loss: 1.7220 - acc: 0.7479 - mean_squared_error: 5503042.0000 - val_loss: 1.7265 - val_acc: 0.7469 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 8/25\n",
            "10197/10197 [==============================] - 7s 644us/sample - loss: 1.6500 - acc: 0.7498 - mean_squared_error: 5503042.5000 - val_loss: 1.6546 - val_acc: 0.7475 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 9/25\n",
            "10197/10197 [==============================] - 7s 691us/sample - loss: 1.5816 - acc: 0.7502 - mean_squared_error: 5503042.0000 - val_loss: 1.6052 - val_acc: 0.7479 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 10/25\n",
            "10197/10197 [==============================] - 7s 665us/sample - loss: 1.5483 - acc: 0.7507 - mean_squared_error: 5503042.0000 - val_loss: 1.5883 - val_acc: 0.7481 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 11/25\n",
            "10197/10197 [==============================] - 7s 678us/sample - loss: 1.5351 - acc: 0.7507 - mean_squared_error: 5503041.5000 - val_loss: 1.5807 - val_acc: 0.7480 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 12/25\n",
            "10197/10197 [==============================] - 7s 670us/sample - loss: 1.5270 - acc: 0.7510 - mean_squared_error: 5503042.5000 - val_loss: 1.5762 - val_acc: 0.7478 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 13/25\n",
            "10197/10197 [==============================] - 7s 660us/sample - loss: 1.5225 - acc: 0.7512 - mean_squared_error: 5503041.5000 - val_loss: 1.5816 - val_acc: 0.7481 - val_mean_squared_error: 5536400.0000\n",
            "Epoch 14/25\n",
            "10197/10197 [==============================] - 7s 674us/sample - loss: 1.5193 - acc: 0.7513 - mean_squared_error: 5503042.5000 - val_loss: 1.5734 - val_acc: 0.7477 - val_mean_squared_error: 5536401.5000\n",
            "Epoch 15/25\n",
            "10197/10197 [==============================] - 7s 673us/sample - loss: 1.5139 - acc: 0.7514 - mean_squared_error: 5503041.0000 - val_loss: 1.5717 - val_acc: 0.7483 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 16/25\n",
            "10197/10197 [==============================] - 7s 667us/sample - loss: 1.5068 - acc: 0.7519 - mean_squared_error: 5503042.0000 - val_loss: 1.5665 - val_acc: 0.7479 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 17/25\n",
            "10197/10197 [==============================] - 7s 670us/sample - loss: 1.5024 - acc: 0.7526 - mean_squared_error: 5503043.0000 - val_loss: 1.5656 - val_acc: 0.7504 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 18/25\n",
            "10197/10197 [==============================] - 7s 652us/sample - loss: 1.4983 - acc: 0.7533 - mean_squared_error: 5503041.0000 - val_loss: 1.5649 - val_acc: 0.7512 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 19/25\n",
            "10197/10197 [==============================] - 7s 702us/sample - loss: 1.4943 - acc: 0.7556 - mean_squared_error: 5503041.5000 - val_loss: 1.5609 - val_acc: 0.7517 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 20/25\n",
            "10197/10197 [==============================] - 7s 658us/sample - loss: 1.4900 - acc: 0.7577 - mean_squared_error: 5503041.0000 - val_loss: 1.5606 - val_acc: 0.7520 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 21/25\n",
            "10197/10197 [==============================] - 7s 659us/sample - loss: 1.4866 - acc: 0.7587 - mean_squared_error: 5503041.5000 - val_loss: 1.5575 - val_acc: 0.7599 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 22/25\n",
            "10197/10197 [==============================] - 7s 670us/sample - loss: 1.4822 - acc: 0.7604 - mean_squared_error: 5503040.5000 - val_loss: 1.5539 - val_acc: 0.7600 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 23/25\n",
            "10197/10197 [==============================] - 7s 663us/sample - loss: 1.4780 - acc: 0.7618 - mean_squared_error: 5503041.5000 - val_loss: 1.5532 - val_acc: 0.7599 - val_mean_squared_error: 5536400.0000\n",
            "Epoch 24/25\n",
            "10197/10197 [==============================] - 7s 697us/sample - loss: 1.4735 - acc: 0.7624 - mean_squared_error: 5503040.0000 - val_loss: 1.5550 - val_acc: 0.7543 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 25/25\n",
            "10197/10197 [==============================] - 7s 657us/sample - loss: 1.4696 - acc: 0.7626 - mean_squared_error: 5503041.0000 - val_loss: 1.5497 - val_acc: 0.7614 - val_mean_squared_error: 5536399.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbafda19fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9vjPm2GCYKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a9893b-cb08-4859-d7ad-4b6dfd8d687c"
      },
      "source": [
        "# base_model=tf.keras.models.load_model(\"drive/MyDrive/model/Less_trained_base.h5\")\n",
        "# base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 113, 64)           16896     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 113, 34809)        2262585   \n",
            "=================================================================\n",
            "Total params: 2,279,481\n",
            "Trainable params: 2,279,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nDxB8O0Dr33",
        "outputId": "af2c76cb-6c6f-4445-8d3a-9988f21b4324"
      },
      "source": [
        "#Evaluating LSTM model on unseen data\n",
        "\n",
        "l,acc,mse=base_model.evaluate(test_x,test_y)\n",
        "print(\"Base model loss for testing set:{}\".format(l))\n",
        "print(\"Base model accuracy for testing set:{}\".format(acc))\n",
        "print(\"Base model MSE for testing set:{}\".format(mse))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1472/1472 [==============================] - 1s 780us/sample - loss: 1.5307 - acc: 0.7672 - mean_squared_error: 5426667.5000\n",
            "Base model loss for testing set:1.5306736075359841\n",
            "Base model accuracy for testing set:0.7672028541564941\n",
            "Base model MSE for testing set:5426667.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V7nQnNrM6ck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ae8ac672-637d-4147-ddb5-a581bf35366d"
      },
      "source": [
        "#Sample translation by base LSTM model\n",
        "translate(\"I am sad\",base_model,False)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['<SOS>', 'ich', 'ist', 'nicht', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jBADUl-Buhn",
        "outputId": "f9dc10ab-251c-4111-f40f-e5efe622f16d"
      },
      "source": [
        "#embedding model starts here-------------------------------------------\n",
        "\n",
        "#Removing singleton axis from 3rd axis\n",
        "#for embedding layer\n",
        "t_x=np.squeeze(train_x,axis=2)\n",
        "v_x=np.squeeze(val_x,axis=2)\n",
        "te_x=np.squeeze(test_x,axis=2)\n",
        "print(t_x.shape)\n",
        "print(v_x.shape)\n",
        "print(te_x.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10197, 31)\n",
            "(3047, 31)\n",
            "(1472, 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQohAY2OPyV8"
      },
      "source": [
        "\n",
        "def embedding_LSTM(m2_lstm_units,lr,embedding_col):\n",
        "  '''\n",
        "  LSTM model with embedding layer\n",
        "  '''\n",
        "  lstm=LSTM(m2_lstm_units,return_sequences=True,activation=\"tanh\")\n",
        "  print(t_x.shape[1])\n",
        "  embed=Embedding(len(ger.vocab_list),embedding_col,input_length=t_x.shape[1])\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation=\"softmax\"))\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(embed)\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(lr),metrics=['accuracy','MeanSquaredError'])\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB5CvJLV5LzC",
        "outputId": "3db8ce01-4cdd-46ea-97a3-a8287949a021"
      },
      "source": [
        "embeded_model=embedding_LSTM(m2_lstm_units,m2_lr,m2_embedding_col)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUWKsmwb5bZB",
        "outputId": "da546586-9598-4071-def9-861cd22e4b1f"
      },
      "source": [
        "#training embedding model\n",
        "embeded_model.fit(t_x,train_y,batch_size=m2_batch_size,epochs=m2_epochs,validation_data=(v_x,val_y))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10197 samples, validate on 3047 samples\n",
            "Epoch 1/30\n",
            "10197/10197 [==============================] - 8s 741us/sample - loss: 3.2681 - acc: 0.6973 - mean_squared_error: 5503041.0000 - val_loss: 1.9890 - val_acc: 0.7282 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 2/30\n",
            "10197/10197 [==============================] - 7s 689us/sample - loss: 1.7437 - acc: 0.7304 - mean_squared_error: 5503043.0000 - val_loss: 1.6639 - val_acc: 0.7329 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 3/30\n",
            "10197/10197 [==============================] - 7s 700us/sample - loss: 1.5771 - acc: 0.7449 - mean_squared_error: 5503040.0000 - val_loss: 1.5940 - val_acc: 0.7508 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 4/30\n",
            "10197/10197 [==============================] - 7s 706us/sample - loss: 1.5154 - acc: 0.7573 - mean_squared_error: 5503041.0000 - val_loss: 1.5517 - val_acc: 0.7554 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 5/30\n",
            "10197/10197 [==============================] - 7s 685us/sample - loss: 1.4696 - acc: 0.7641 - mean_squared_error: 5503041.5000 - val_loss: 1.5265 - val_acc: 0.7584 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 6/30\n",
            "10197/10197 [==============================] - 7s 702us/sample - loss: 1.4301 - acc: 0.7722 - mean_squared_error: 5503041.0000 - val_loss: 1.4986 - val_acc: 0.7686 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 7/30\n",
            "10197/10197 [==============================] - 7s 715us/sample - loss: 1.3822 - acc: 0.7820 - mean_squared_error: 5503042.0000 - val_loss: 1.4595 - val_acc: 0.7750 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 8/30\n",
            "10197/10197 [==============================] - 7s 700us/sample - loss: 1.3285 - acc: 0.7901 - mean_squared_error: 5503043.0000 - val_loss: 1.4273 - val_acc: 0.7790 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 9/30\n",
            "10197/10197 [==============================] - 7s 704us/sample - loss: 1.2777 - acc: 0.7963 - mean_squared_error: 5503042.5000 - val_loss: 1.4013 - val_acc: 0.7826 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 10/30\n",
            "10197/10197 [==============================] - 7s 722us/sample - loss: 1.2317 - acc: 0.8022 - mean_squared_error: 5503041.5000 - val_loss: 1.3817 - val_acc: 0.7877 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 11/30\n",
            "10197/10197 [==============================] - 7s 725us/sample - loss: 1.1917 - acc: 0.8064 - mean_squared_error: 5503041.0000 - val_loss: 1.3661 - val_acc: 0.7899 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 12/30\n",
            "10197/10197 [==============================] - 7s 690us/sample - loss: 1.1540 - acc: 0.8097 - mean_squared_error: 5503042.0000 - val_loss: 1.3522 - val_acc: 0.7902 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 13/30\n",
            "10197/10197 [==============================] - 7s 704us/sample - loss: 1.1193 - acc: 0.8129 - mean_squared_error: 5503043.0000 - val_loss: 1.3477 - val_acc: 0.7918 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 14/30\n",
            "10197/10197 [==============================] - 7s 679us/sample - loss: 1.0861 - acc: 0.8158 - mean_squared_error: 5503042.5000 - val_loss: 1.3389 - val_acc: 0.7912 - val_mean_squared_error: 5536400.0000\n",
            "Epoch 15/30\n",
            "10197/10197 [==============================] - 7s 703us/sample - loss: 1.0547 - acc: 0.8186 - mean_squared_error: 5503040.5000 - val_loss: 1.3372 - val_acc: 0.7937 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 16/30\n",
            "10197/10197 [==============================] - 7s 710us/sample - loss: 1.0238 - acc: 0.8216 - mean_squared_error: 5503040.0000 - val_loss: 1.3321 - val_acc: 0.7940 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 17/30\n",
            "10197/10197 [==============================] - 7s 676us/sample - loss: 0.9934 - acc: 0.8244 - mean_squared_error: 5503041.0000 - val_loss: 1.3270 - val_acc: 0.7947 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 18/30\n",
            "10197/10197 [==============================] - 7s 663us/sample - loss: 0.9646 - acc: 0.8268 - mean_squared_error: 5503041.0000 - val_loss: 1.3281 - val_acc: 0.7962 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 19/30\n",
            "10197/10197 [==============================] - 7s 696us/sample - loss: 0.9376 - acc: 0.8289 - mean_squared_error: 5503043.0000 - val_loss: 1.3308 - val_acc: 0.7968 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 20/30\n",
            "10197/10197 [==============================] - 7s 692us/sample - loss: 0.9093 - acc: 0.8319 - mean_squared_error: 5503041.0000 - val_loss: 1.3281 - val_acc: 0.7968 - val_mean_squared_error: 5536400.0000\n",
            "Epoch 21/30\n",
            "10197/10197 [==============================] - 7s 663us/sample - loss: 0.8826 - acc: 0.8349 - mean_squared_error: 5503040.5000 - val_loss: 1.3305 - val_acc: 0.7976 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 22/30\n",
            "10197/10197 [==============================] - 7s 657us/sample - loss: 0.8562 - acc: 0.8380 - mean_squared_error: 5503041.0000 - val_loss: 1.3379 - val_acc: 0.7979 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 23/30\n",
            "10197/10197 [==============================] - 7s 654us/sample - loss: 0.8312 - acc: 0.8408 - mean_squared_error: 5503041.0000 - val_loss: 1.3438 - val_acc: 0.7975 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 24/30\n",
            "10197/10197 [==============================] - 7s 671us/sample - loss: 0.8086 - acc: 0.8437 - mean_squared_error: 5503041.5000 - val_loss: 1.3489 - val_acc: 0.7984 - val_mean_squared_error: 5536400.0000\n",
            "Epoch 25/30\n",
            "10197/10197 [==============================] - 7s 668us/sample - loss: 0.7856 - acc: 0.8466 - mean_squared_error: 5503041.5000 - val_loss: 1.3491 - val_acc: 0.7985 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 26/30\n",
            "10197/10197 [==============================] - 7s 667us/sample - loss: 0.7633 - acc: 0.8502 - mean_squared_error: 5503041.0000 - val_loss: 1.3513 - val_acc: 0.7982 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 27/30\n",
            "10197/10197 [==============================] - 7s 668us/sample - loss: 0.7423 - acc: 0.8534 - mean_squared_error: 5503041.0000 - val_loss: 1.3591 - val_acc: 0.7986 - val_mean_squared_error: 5536400.0000\n",
            "Epoch 28/30\n",
            "10197/10197 [==============================] - 7s 670us/sample - loss: 0.7235 - acc: 0.8564 - mean_squared_error: 5503041.0000 - val_loss: 1.3654 - val_acc: 0.7991 - val_mean_squared_error: 5536401.0000\n",
            "Epoch 29/30\n",
            "10197/10197 [==============================] - 7s 670us/sample - loss: 0.7054 - acc: 0.8589 - mean_squared_error: 5503040.5000 - val_loss: 1.3709 - val_acc: 0.7994 - val_mean_squared_error: 5536400.5000\n",
            "Epoch 30/30\n",
            "10197/10197 [==============================] - 7s 668us/sample - loss: 0.6884 - acc: 0.8616 - mean_squared_error: 5503041.5000 - val_loss: 1.3728 - val_acc: 0.7972 - val_mean_squared_error: 5536401.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbafef9b748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjapHrel-XV3",
        "outputId": "cd5bc14e-c0c4-4925-fc78-c5cdcdbd1d1c"
      },
      "source": [
        "embeded_model=tf.keras.models.load_model(\"drive/MyDrive/embedded_15000.h5\")\n",
        "l,acc=embeded_model.evaluate(te_x,test_y)\n",
        "print(\"Embedded model loss for testing set:{}\".format(l))\n",
        "print(\"Embedded model accuracy for testing set:{}\".format(acc))\n",
        "#print(\"Embedded model MSE for testing set:{}\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1472/1472 [==============================] - 1s 794us/sample - loss: 0.7717 - acc: 0.8711\n",
            "Embedded model loss for testing set:0.7716904360315074\n",
            "Embedded model accuracy for testing set:0.871077299118042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS2mEhvO-0kE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c5862f17-00bf-4309-d084-5ed2cd15b596"
      },
      "source": [
        "translate(\"I am sad\",embeded_model,True)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['<SOS>', 'ich', 'bin', 'traurig', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6eCU8-iy7Ii"
      },
      "source": [
        "#Hyperparameter tuning starts here\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
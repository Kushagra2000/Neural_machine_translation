{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_translation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMQA85PWSPHq08fQoVW2uU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kushagra2000/Neural_machine_translation/blob/main/Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "a_wTnIFR8vNu",
        "outputId": "d95b0080-c7f5-4f71-8b14-35fae7724937"
      },
      "source": [
        "#imports\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Activation,InputLayer\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eacpqiV9DTc",
        "outputId": "20db15f3-bd2d-4d0a-e5f6-c317e88549b3"
      },
      "source": [
        "#Upload the deu.txt file and put it in the Data Folder\n",
        "#!ls Data/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deu.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjnci4B5Aywh"
      },
      "source": [
        "#reading lines from thge txt file\n",
        "# with open('Data/deu.txt','r',encoding='utf-8') as f:\n",
        "#   lines=(f.readlines())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDt6gkPfKhs"
      },
      "source": [
        "#Hyperparameters go here\n",
        "test_size=0.3\n",
        "m1_lr=0.005\n",
        "m2_lr=0.005\n",
        "batch_size=75\n",
        "m1_lstm_units=64\n",
        "m2_lstm_units=64\n",
        "m1_epochs=12\n",
        "m2_epochs=12\n",
        "m1_batch_size=128\n",
        "m2_batch_size=128"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSnn6gGCBEy5"
      },
      "source": [
        "#removing the unnecessary data and obtaining sentence pairs \n",
        "def process_text(lines,translate_mode):\n",
        "  ''' \n",
        "  Takes a list of tab seperated\n",
        "  English and German sentences as input \n",
        "  and returns dataframe of processed\n",
        "  English and German sentence pairs\n",
        "  '''\n",
        "  proc_lines=[]\n",
        "  if translate_mode==False:\n",
        "    for line in lines:\n",
        "      line=line.strip() #to remove newlines at the end of a sentence\n",
        "      line=line.split(\"\\t\") #splitting by tabs\n",
        "      line=line[:-1]  #remove contributing information\n",
        "      \n",
        "      line[0]=''.join(c for c in unicodedata.normalize('NFD', line[0]) if unicodedata.category(c) != 'Mn')\n",
        "      line[0]=line[0].encode('utf8','ignore').decode('utf8')\n",
        "      line[0]=line[0].replace(u'\\u200b',' ')\n",
        "      line[0]=line[0].lower()\n",
        "      line[0]=line[0].replace('\\xa0', ' ')\n",
        "      line[0]=re.sub(r\"([.,?!;])\",r\" \\1 \",line[0])   #adding spaces before and after punctuation\n",
        "      line[0]=re.sub(r\"[0-9]\",\" \",line[0])\n",
        "      line[0]=re.sub(r'[\"]',\" \",line[0])\n",
        "      line[0]=re.sub(r\"[']\",\"\",line[0])\n",
        "      line[0]=re.sub(r\"[%-]\",\" \",line[0])\n",
        "      line[0]=re.sub(r\"[:]\",\" \",line[0])\n",
        "      line[0]=re.sub(r'[\" \"]+',\" \",line[0])  #removing excess spaces\n",
        "      line[0]=line[0].strip() #removing spaces from the end of string\n",
        "      line[0]=\"<SOS> \"+line[0]+\" <EOS>\"\n",
        "\n",
        "      line[1]=''.join(c for c in unicodedata.normalize('NFD', line[1]) if unicodedata.category(c) != 'Mn')\n",
        "      line[1]=line[1].replace(u'\\u200b',' ')\n",
        "      line[1]=line[1].replace('\\xa0', ' ')\n",
        "      line[1]=line[1].lower()\n",
        "      line[1]=re.sub(r\"([.,?!;])\",r\" \\1 \",line[1])\n",
        "      line[1]=re.sub(r\"[0-9]\",r\" \",line[1])\n",
        "      line[1]=re.sub(r'[\"]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[—]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[„]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[“]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[–]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[‘‚]',\"\",line[1])\n",
        "      line[1]=re.sub(r\"[']\",\"\",line[1])\n",
        "      line[1]=re.sub(r\"[%()-]\",\" \",line[1])\n",
        "      line[1]=re.sub(r\"[:]\",\" \",line[1])\n",
        "      line[1]=re.sub(r'[\" \"]+',\" \",line[1])\n",
        "      line[1]=line[1].strip()\n",
        "      line[1]=\"<SOS> \"+line[1]+\" <EOS>\"\n",
        "\n",
        "      proc_lines.append(line) \n",
        "    return pd.DataFrame.from_records(data=proc_lines,columns=['eng','ger'])\n",
        "  else:\n",
        "    lines=lines.strip()\n",
        "    lines=''.join(c for c in unicodedata.normalize('NFD', lines) if unicodedata.category(c) != 'Mn')\n",
        "    lines=lines.encode('utf8','ignore').decode('utf8')\n",
        "    lines=lines.replace(u'\\u200b',' ')\n",
        "    lines=lines.lower()\n",
        "    lines=lines.replace('\\xa0', ' ')\n",
        "    lines=re.sub(r\"([.,?!;])\",r\" \\1 \",lines)   #adding spaces before and after punctuation\n",
        "    lines=re.sub(r\"[0-9]\",\" \",lines)\n",
        "    lines=re.sub(r'[\"]',\" \",lines)\n",
        "    lines=re.sub(r\"[']\",\"\",lines)\n",
        "    lines=re.sub(r\"[%-]\",\" \",lines)\n",
        "    lines=re.sub(r\"[:]\",\" \",lines)\n",
        "    lines=re.sub(r'[\" \"]+',\" \",lines)  #removing excess spaces\n",
        "    lines=lines.strip() #removing spaces from the end of string\n",
        "    lines=\"<SOS> \"+lines+\" <EOS>\"\n",
        "    return lines\n",
        "\n",
        "  \n",
        "     \n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "vWgVr4xOBK33",
        "outputId": "6df0e3e0-0577-462f-cf9d-2c4608b2641a"
      },
      "source": [
        "#df=process_text(lines,False)\n",
        "df=pd.read_csv('data/data.csv')\n",
        "print(df.head(10))\n",
        "df[df['eng']==\"<SOS> tom will be here soon . how soon ? <EOS>\"].iloc[0,1]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  eng                         ger\n",
            "0    <SOS> go . <EOS>           <SOS> geh . <EOS>\n",
            "1    <SOS> hi . <EOS>         <SOS> hallo ! <EOS>\n",
            "2    <SOS> hi . <EOS>     <SOS> gruß gott ! <EOS>\n",
            "3   <SOS> run ! <EOS>          <SOS> lauf ! <EOS>\n",
            "4   <SOS> run . <EOS>          <SOS> lauf ! <EOS>\n",
            "5   <SOS> wow ! <EOS>    <SOS> potzdonner ! <EOS>\n",
            "6   <SOS> wow ! <EOS>  <SOS> donnerwetter ! <EOS>\n",
            "7  <SOS> fire ! <EOS>         <SOS> feuer ! <EOS>\n",
            "8  <SOS> help ! <EOS>         <SOS> hilfe ! <EOS>\n",
            "9  <SOS> help ! <EOS>       <SOS> zu hulf ! <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<SOS> tom wird bald hier sein . was heißt bald ? <EOS>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGB8vaIOfW5r"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "DNmFdtxhtnjz",
        "outputId": "fd853d30-1ecd-4c16-9a15-23755f6a84f8"
      },
      "source": [
        "df.tail(10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224410</th>\n",
              "      <td>&lt;SOS&gt; as a prank , some students let three goa...</td>\n",
              "      <td>&lt;SOS&gt; als streich ließen einige schuler drei z...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224411</th>\n",
              "      <td>&lt;SOS&gt; the small crowd at hiroshima peace memor...</td>\n",
              "      <td>&lt;SOS&gt; um . uhr vormittags , dem genauen zeitpu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224412</th>\n",
              "      <td>&lt;SOS&gt; in todays world , we have to equip all o...</td>\n",
              "      <td>&lt;SOS&gt; in der heutigen welt mussen wir all unse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224413</th>\n",
              "      <td>&lt;SOS&gt; death is something that were often disco...</td>\n",
              "      <td>&lt;SOS&gt; wir werden oft davon abgehalten , uber d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224414</th>\n",
              "      <td>&lt;SOS&gt; at a moment when our economy is growing ...</td>\n",
              "      <td>&lt;SOS&gt; in einem moment , in dem unsere wirtscha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224415</th>\n",
              "      <td>&lt;SOS&gt; even if some sentences by non native spe...</td>\n",
              "      <td>&lt;SOS&gt; auch wenn satze von nichtmuttersprachler...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224416</th>\n",
              "      <td>&lt;SOS&gt; if someone who doesnt know your backgrou...</td>\n",
              "      <td>&lt;SOS&gt; wenn jemand , der deine herkunft nicht k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224417</th>\n",
              "      <td>&lt;SOS&gt; if someone who doesnt know your backgrou...</td>\n",
              "      <td>&lt;SOS&gt; wenn jemand fremdes dir sagt , dass du d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224418</th>\n",
              "      <td>&lt;SOS&gt; if someone who doesnt know your backgrou...</td>\n",
              "      <td>&lt;SOS&gt; wenn jemand , der nicht weiß , woher man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224419</th>\n",
              "      <td>&lt;SOS&gt; doubtless there exists in this world pre...</td>\n",
              "      <td>&lt;SOS&gt; ohne zweifel findet sich auf dieser welt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      eng                                                ger\n",
              "224410  <SOS> as a prank , some students let three goa...  <SOS> als streich ließen einige schuler drei z...\n",
              "224411  <SOS> the small crowd at hiroshima peace memor...  <SOS> um . uhr vormittags , dem genauen zeitpu...\n",
              "224412  <SOS> in todays world , we have to equip all o...  <SOS> in der heutigen welt mussen wir all unse...\n",
              "224413  <SOS> death is something that were often disco...  <SOS> wir werden oft davon abgehalten , uber d...\n",
              "224414  <SOS> at a moment when our economy is growing ...  <SOS> in einem moment , in dem unsere wirtscha...\n",
              "224415  <SOS> even if some sentences by non native spe...  <SOS> auch wenn satze von nichtmuttersprachler...\n",
              "224416  <SOS> if someone who doesnt know your backgrou...  <SOS> wenn jemand , der deine herkunft nicht k...\n",
              "224417  <SOS> if someone who doesnt know your backgrou...  <SOS> wenn jemand fremdes dir sagt , dass du d...\n",
              "224418  <SOS> if someone who doesnt know your backgrou...  <SOS> wenn jemand , der nicht weiß , woher man...\n",
              "224419  <SOS> doubtless there exists in this world pre...  <SOS> ohne zweifel findet sich auf dieser welt..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zctawZ8xGF_R"
      },
      "source": [
        "class Vocab_builder():\n",
        "  def __init__(self,lang,series):\n",
        "    self.lang=lang\n",
        "    self.data=series\n",
        "  def tokenize(self,line):\n",
        "    return line.split(' ')\n",
        "  def build_vocab(self):\n",
        "    self.uniq_words=set()\n",
        "    # self.uniq_words.add('<PAD>')\n",
        "    # self.uniq_words.add('<SOS>')\n",
        "    # self.uniq_words.add('<EOS>')\n",
        "    self.maxlen=0\n",
        "    count=3\n",
        "    self.num_list=[]\n",
        "    for index,line in self.data.items():\n",
        "      self.word_list=self.tokenize(line)\n",
        "      self.maxlen=max(len(self.word_list),self.maxlen)\n",
        "      for word in self.word_list:\n",
        "        if(word not in self.uniq_words and word!='<EOS>' and word!='<SOS>'):\n",
        "          self.uniq_words.add(word)\n",
        "          self.num_list.append(count)\n",
        "          count+=1\n",
        "      \n",
        "    self.vocab_list=['<PAD>','<SOS>','<EOS>']+sorted(list(self.uniq_words))\n",
        "    self.num_list=[0,1,2]+self.num_list\n",
        "    print(\"Built vocabulary having {} elements\".format(len(self.vocab_list)))\n",
        "    print(\"Largest sentence length (with tags):{}\".format(self.maxlen))\n",
        "    return dict(zip(self.vocab_list,self.num_list)),dict(zip(self.num_list,self.vocab_list))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JVuh6iKohIC"
      },
      "source": [
        "eng=Vocab_builder('eng',df['eng'])\n",
        "ger=Vocab_builder('ger',df['ger'])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL4ZAsYizIsd",
        "outputId": "e445c0d6-d7d2-4ece-c122-18bff10d5b96"
      },
      "source": [
        "eng_w2i,eng_i2w=eng.build_vocab()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built vocabulary having 15957 elements\n",
            "Largest sentence length (with tags):113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsH4pLi3zOcS",
        "outputId": "b2a2b970-9011-4804-e0d4-466d5de5999e"
      },
      "source": [
        "#checking for special characters in English dictionary\n",
        "for i in sorted (eng_w2i.keys())[:20] :  \n",
        "     print(i, end = \" \") "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! $ , . / ; <EOS> <PAD> <SOS> ? a aah aardvark aardvarks aarhus abacus abandon abandoned abated abating "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWE4mEkcMF2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c945366-bd37-412b-f785-3e883548fe46"
      },
      "source": [
        "ger_w2i,ger_i2w=ger.build_vocab()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built vocabulary having 34809 elements\n",
            "Largest sentence length (with tags):86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rglyUxdDxD3Z",
        "outputId": "79f3c9d9-ad2e-44c6-a463-4d6bd691fa84"
      },
      "source": [
        "#checking for special characters in German dictionary\n",
        "for i in sorted (ger_w2i.keys())[:20] :  \n",
        "     print(i, end = \" \") "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! $ + , . / ; <EOS> <PAD> <SOS> ? a aal aale aalglatter aalte aalten aarhus ab abakus "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HctDyjqmxKuX"
      },
      "source": [
        "def sent_to_ind(sentence,lang):\n",
        "  ind_list=[]\n",
        "  if lang=='eng':\n",
        "    tokens=eng.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      ind_list.append(eng_w2i[token])\n",
        "    while len(ind_list)<eng.maxlen:\n",
        "      ind_list.append(0)\n",
        "  else:\n",
        "    tokens=ger.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      ind_list.append(ger_w2i[token])\n",
        "    while len(ind_list)<eng.maxlen:\n",
        "      ind_list.append(0)\n",
        "    \n",
        "  return np.array(ind_list)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix5EpSK3eQod",
        "outputId": "55aea6df-7e46-4783-cc39-cf29b3677c39"
      },
      "source": [
        "test_lis=sent_to_ind('<SOS> tom wird bald hier sein . was heißt bald ? <EOS>','ger')\n",
        "print(len(test_lis))\n",
        "print(test_lis)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113\n",
            "[    1 28295 33314  3110 14408 25586     7 32497 13967  3110    10     2\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfhMnYBhXb8",
        "outputId": "7a4758c9-e930-4184-b793-555cbc087ab7"
      },
      "source": [
        "test_lis=sent_to_ind(\"<SOS> tom will be here soon . how soon ? <EOS>\",'eng')\n",
        "print(len(test_lis))\n",
        "print(test_lis)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113\n",
            "[    1 14421 15646  1208  6571 13049     6  6822 13049     9     2     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylompezso3K8"
      },
      "source": [
        "#Shuffling the dataset\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VENEOHriC99"
      },
      "source": [
        "#splitting the data into training and testing sets\n",
        "\n",
        "# train_x,test_x,train_y,test_y=train_test_split(df['eng'],df['ger'],test_size=0.1,random_state=42)\n",
        "# train_x,val_x,train_y,val_y=train_test_split(train_x,train_y,test_size=0.23,random_state=42)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NetMWl-AtVvi"
      },
      "source": [
        "def sent_to_np(series,lang,translate_mode):\n",
        "  ret_list=[]\n",
        "  if translate_mode==False :\n",
        "    if lang=='eng':\n",
        "      for index,val in series.items():\n",
        "        ret_list.append(sent_to_ind(val,'eng'))\n",
        "    else:\n",
        "      for index,val in series.items():\n",
        "        ret_list.append(sent_to_ind(val,'ger'))\n",
        "    \n",
        "    ret_list=np.array(ret_list)\n",
        "    return np.expand_dims(ret_list,axis=2)\n",
        "  else:\n",
        "    ans=sent_to_ind(series,'eng')\n",
        "    ans=np.expand_dims(ans,axis=0)\n",
        "    ans=np.expand_dims(ans,axis=2)\n",
        "    return ans\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdCHrrTaSqww"
      },
      "source": [
        "# train_x=sent_to_np(train_x,'eng',False)\n",
        "# train_y=sent_to_np(train_y,'ger',False)\n",
        "# test_x=sent_to_np(test_x,'eng',False)\n",
        "# test_y=sent_to_np(test_y,'ger',False)\n",
        "# val_x=sent_to_np(val_x,'eng',False)\n",
        "# val_y=sent_to_np(val_y,'ger',False)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEbhTzocTrYu"
      },
      "source": [
        "#loading training,testing and validation data\n",
        "train_x=np.load(\"data/training/train_x.npy\")\n",
        "train_y=np.load(\"data/training/train_y.npy\")\n",
        "\n",
        "test_x=np.load(\"data/testing/test_x.npy\")\n",
        "test_y=np.load(\"data/testing/test_y.npy\")\n",
        "\n",
        "val_x=np.load(\"data/validation/val_x.npy\")\n",
        "val_y=np.load(\"data/validation/val_y.npy\")\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp4PP4UR9d8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fab6b4f-397d-40c6-e86b-8e7af6bf8b7a"
      },
      "source": [
        "#Input shape denotes [batch,no.of timesteps,features]\n",
        "print(train_x.shape)\n",
        "print(test_x.shape)\n",
        "print(val_x.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(155523, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zt6VKybF7WK"
      },
      "source": [
        "def translate(sentence,mod,pad_tol):\n",
        "  ans=\"\"\n",
        "  preproc_sent=process_text(sentence,True)\n",
        "  model_inp=sent_to_np(preproc_sent,'eng',True)\n",
        "  pred=mod.predict(model_input)\n",
        "  count=0\n",
        "  for i in pred[0]:\n",
        "    ind=np.argmax(i)\n",
        "    if (ind==0):\n",
        "      count+=1\n",
        "    if count<pad_tol:\n",
        "      ans+=ger_i2w[ind]\n",
        "    else:\n",
        "      return ans\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_cqENbVFpVI"
      },
      "source": [
        "#training starts here ----------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEFKmQmibP_y"
      },
      "source": [
        "def base_LSTM_model(eng_arr,op_vocab_size,lr):\n",
        "  lstm=LSTM(m1_lstm_units,return_sequences=True,activation='tanh')\n",
        "  dense=Dense(op_vocab_size,activation='softmax')\n",
        "  layer_at_t=TimeDistributed(dense)\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(InputLayer(eng_arr.shape[1:]))\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(lr),metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWOrrfsRNOcT"
      },
      "source": [
        "#base_model=base_LSTM_model(train_x,len(ger.vocab_list),m1_lr)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzsf600cPN9w",
        "outputId": "06f441fc-7abe-4860-ee99-5c7deef37a9e"
      },
      "source": [
        "#base_model.fit(train_x,train_y,m1_batch_size,m1_epochs,validation_data=(val_x,val_y))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 155523 samples, validate on 46455 samples\n",
            "Epoch 1/12\n",
            "155523/155523 [==============================] - 658s 4ms/sample - loss: 0.5786 - acc: 0.9275 - val_loss: 0.4472 - val_acc: 0.9302\n",
            "Epoch 2/12\n",
            "155523/155523 [==============================] - 655s 4ms/sample - loss: 0.4451 - acc: 0.9302 - val_loss: 0.4423 - val_acc: 0.9313\n",
            "Epoch 3/12\n",
            "155523/155523 [==============================] - 661s 4ms/sample - loss: 0.4406 - acc: 0.9306 - val_loss: 0.4399 - val_acc: 0.9312\n",
            "Epoch 4/12\n",
            "155523/155523 [==============================] - 658s 4ms/sample - loss: 0.4375 - acc: 0.9309 - val_loss: 0.4374 - val_acc: 0.9316\n",
            "Epoch 5/12\n",
            "155523/155523 [==============================] - 659s 4ms/sample - loss: 0.4362 - acc: 0.9310 - val_loss: 0.4370 - val_acc: 0.9310\n",
            "Epoch 6/12\n",
            "155523/155523 [==============================] - 661s 4ms/sample - loss: 0.4344 - acc: 0.9311 - val_loss: 0.4350 - val_acc: 0.9313\n",
            "Epoch 7/12\n",
            "155523/155523 [==============================] - 657s 4ms/sample - loss: 0.4330 - acc: 0.9312 - val_loss: 0.4346 - val_acc: 0.9311\n",
            "Epoch 8/12\n",
            "155523/155523 [==============================] - 655s 4ms/sample - loss: 0.4322 - acc: 0.9312 - val_loss: 0.4343 - val_acc: 0.9311\n",
            "Epoch 9/12\n",
            "155523/155523 [==============================] - 654s 4ms/sample - loss: 0.4321 - acc: 0.9313 - val_loss: 0.4353 - val_acc: 0.9307\n",
            "Epoch 10/12\n",
            "155523/155523 [==============================] - 657s 4ms/sample - loss: 0.4319 - acc: 0.9313 - val_loss: 0.4362 - val_acc: 0.9316\n",
            "Epoch 11/12\n",
            "155523/155523 [==============================] - 661s 4ms/sample - loss: 0.4317 - acc: 0.9313 - val_loss: 0.4345 - val_acc: 0.9316\n",
            "Epoch 12/12\n",
            "155523/155523 [==============================] - 663s 4ms/sample - loss: 0.4311 - acc: 0.9314 - val_loss: 0.4340 - val_acc: 0.9317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f767a966d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9vjPm2GCYKh"
      },
      "source": [
        "base_model=tf.keras.models.load_model(\"model/MT_base_RNN.h5\")\n",
        "base_model.summary()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nDxB8O0Dr33",
        "outputId": "512e6d02-69ca-4e1d-ae64-0f2fb6c46334"
      },
      "source": [
        "l,acc=base_model.evaluate(test_x,test_y)\n",
        "print(\"Base model loss for testing set:{}\".format(l))\n",
        "print(\"Base model accuracy for testing set:{}\".format(acc))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22442/22442 [==============================] - 101s 5ms/sample - loss: 0.4346 - acc: 0.9315\n",
            "Base model loss:0.43460041285623535\n",
            "Base model accuracy:0.9315182566642761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V7nQnNrM6ck"
      },
      "source": [
        "translate(\"hello there how are you doing\",base_model)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQohAY2OPyV8",
        "outputId": "b78d47db-2a54-42be-9c87-65f403ed2762"
      },
      "source": [
        "def embedding_LSTM(eng_arr,op_vocab_size,lr):\n",
        "  "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 113, 34809)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[4.3552777e-16, 9.9999917e-01, 4.6834449e-19, ...,\n",
              "         9.8062751e-16, 6.6480778e-16, 9.3407278e-18],\n",
              "        [1.2074879e-05, 1.5622851e-07, 1.7145994e-07, ...,\n",
              "         1.5769974e-08, 6.8593167e-08, 3.8900536e-09],\n",
              "        [2.3691875e-03, 2.9970595e-10, 2.1579079e-03, ...,\n",
              "         6.5130521e-08, 7.6315371e-07, 2.1661398e-08],\n",
              "        ...,\n",
              "        [9.9999309e-01, 3.6652548e-22, 6.2503756e-07, ...,\n",
              "         2.3464938e-13, 1.8469766e-13, 2.0448496e-13],\n",
              "        [9.9999309e-01, 3.6652548e-22, 6.2503756e-07, ...,\n",
              "         2.3464938e-13, 1.8469766e-13, 2.0448496e-13],\n",
              "        [9.9999309e-01, 3.6652548e-22, 6.2503756e-07, ...,\n",
              "         2.3464938e-13, 1.8469766e-13, 2.0448496e-13]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfqYYqA5Ou5s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-4K2HI3_RBvxi7ln2M30dSS8qpHvCFTH",
      "authorship_tag": "ABX9TyO//L4kcjmKpm1mySPoK6P8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kushagra2000/Neural_machine_translation/blob/main/Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "a_wTnIFR8vNu",
        "outputId": "a60b5d67-0e1f-48bc-fcd0-3f7c4a92810a"
      },
      "source": [
        "#imports\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Activation,InputLayer,Embedding\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy,categorical_crossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# !pip install -q -U keras-tuner\n",
        "# import kerastuner as kt \n",
        "import IPython\n",
        "from keras.utils import to_categorical\n",
        "!pip install bleu\n",
        "from bleu import list_bleu\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "Requirement already satisfied: bleu in /usr/local/lib/python3.6/dist-packages (0.3)\n",
            "Requirement already satisfied: efficiency in /usr/local/lib/python3.6/dist-packages (from bleu) (0.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from efficiency->bleu) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (53.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.1.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu) (3.7.4.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjnci4B5Aywh"
      },
      "source": [
        "#reading lines from the txt file\n",
        "num_examples=20000\n",
        "with open('drive/MyDrive/deu.txt','r',encoding='utf-8') as f:\n",
        "  lines=(f.readlines())\n",
        "lines=lines[:num_examples]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDt6gkPfKhs"
      },
      "source": [
        "#Hyperparameters go here\n",
        "\n",
        "test_size=0.3\n",
        "m1_lr=0.001\n",
        "m2_lr=0.005\n",
        "m1_lstm_units=64\n",
        "m2_lstm_units=64\n",
        "m1_epochs=25\n",
        "m2_epochs=30\n",
        "m1_batch_size=128\n",
        "m2_batch_size=128\n",
        "m2_embedding_col=64"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWgVr4xOBK33"
      },
      "source": [
        "#reading the dataset\n",
        "df=pd.read_csv('drive/MyDrive/dataset.csv',index_col=0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "yuwwIEeipzZp",
        "outputId": "2ab8fc33-a429-4a75-8fa9-f2216743a574"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;SOS&gt; how arrogant ! &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; wie arrogant ! &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;SOS&gt; please get tom . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; bitte hol tom . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;SOS&gt; go look for it . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; geh es suchen ! &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;SOS&gt; she disappeared . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; sie verschwand . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;SOS&gt; that book is old . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; das buch ist alt . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;SOS&gt; hold on a moment . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; augenblick mal ! &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;SOS&gt; what is truth ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; was ist wahrheit ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;SOS&gt; ive been better . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; es ging mir schon besser . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;SOS&gt; why is he here ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; warum ist er hier ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;SOS&gt; hes your friend . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; er ist dein freund . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              eng                                     ger\n",
              "0      <SOS> how arrogant ! <EOS>              <SOS> wie arrogant ! <EOS>\n",
              "1    <SOS> please get tom . <EOS>             <SOS> bitte hol tom . <EOS>\n",
              "2    <SOS> go look for it . <EOS>             <SOS> geh es suchen ! <EOS>\n",
              "3   <SOS> she disappeared . <EOS>            <SOS> sie verschwand . <EOS>\n",
              "4  <SOS> that book is old . <EOS>          <SOS> das buch ist alt . <EOS>\n",
              "5  <SOS> hold on a moment . <EOS>            <SOS> augenblick mal ! <EOS>\n",
              "6     <SOS> what is truth ? <EOS>          <SOS> was ist wahrheit ? <EOS>\n",
              "7   <SOS> ive been better . <EOS>  <SOS> es ging mir schon besser . <EOS>\n",
              "8    <SOS> why is he here ? <EOS>         <SOS> warum ist er hier ? <EOS>\n",
              "9   <SOS> hes your friend . <EOS>        <SOS> er ist dein freund . <EOS>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "DNmFdtxhtnjz",
        "outputId": "5888962f-312c-4c8c-f846-a82df29b1e5a"
      },
      "source": [
        "df.tail(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14840</th>\n",
              "      <td>&lt;SOS&gt; here is your bag . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; deine tasche ist hier . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14841</th>\n",
              "      <td>&lt;SOS&gt; read it aloud . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; lies es vor . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14842</th>\n",
              "      <td>&lt;SOS&gt; i thought hard . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich dachte grundlich nach . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14843</th>\n",
              "      <td>&lt;SOS&gt; i must obey tom . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich muss tom gehorchen . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14844</th>\n",
              "      <td>&lt;SOS&gt; we are students . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; wir sind studenten . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14845</th>\n",
              "      <td>&lt;SOS&gt; dont leave ! &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; gehe nicht weg ! &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14846</th>\n",
              "      <td>&lt;SOS&gt; he doesnt sleep . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; er schlaft nicht . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14847</th>\n",
              "      <td>&lt;SOS&gt; is tom good ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ist tom brav ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14848</th>\n",
              "      <td>&lt;SOS&gt; didnt tom smile ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; tom lachelte nicht ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14849</th>\n",
              "      <td>&lt;SOS&gt; tom felt sad . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; tom fuhlte sich traurig . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  eng                                      ger\n",
              "14840  <SOS> here is your bag . <EOS>      <SOS> deine tasche ist hier . <EOS>\n",
              "14841     <SOS> read it aloud . <EOS>                <SOS> lies es vor . <EOS>\n",
              "14842    <SOS> i thought hard . <EOS>  <SOS> ich dachte grundlich nach . <EOS>\n",
              "14843   <SOS> i must obey tom . <EOS>     <SOS> ich muss tom gehorchen . <EOS>\n",
              "14844   <SOS> we are students . <EOS>         <SOS> wir sind studenten . <EOS>\n",
              "14845        <SOS> dont leave ! <EOS>             <SOS> gehe nicht weg ! <EOS>\n",
              "14846   <SOS> he doesnt sleep . <EOS>           <SOS> er schlaft nicht . <EOS>\n",
              "14847       <SOS> is tom good ? <EOS>               <SOS> ist tom brav ? <EOS>\n",
              "14848   <SOS> didnt tom smile ? <EOS>         <SOS> tom lachelte nicht ? <EOS>\n",
              "14849      <SOS> tom felt sad . <EOS>    <SOS> tom fuhlte sich traurig . <EOS>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zctawZ8xGF_R"
      },
      "source": [
        "class Vocab_builder():\n",
        "  '''\n",
        "  Builds vocabulary and \n",
        "  word to index and index to word dictionaries\n",
        "  from dataset\n",
        "  '''\n",
        "  def __init__(self,lang,series):\n",
        "    self.lang=lang\n",
        "    self.data=series\n",
        "  def tokenize(self,line):\n",
        "    return line.split(' ')\n",
        "  def build_vocab(self):\n",
        "    self.uniq_words=set()\n",
        "    \n",
        "    self.maxlen=0\n",
        "    count=3\n",
        "    self.num_list=[]\n",
        "    for index,line in self.data.items():\n",
        "      self.word_list=self.tokenize(line)\n",
        "      self.maxlen=max(len(self.word_list),self.maxlen)\n",
        "      for word in self.word_list:\n",
        "        if(word not in self.uniq_words and word!='<EOS>' and word!='<SOS>'):\n",
        "          self.uniq_words.add(word)\n",
        "          self.num_list.append(count)\n",
        "          count+=1\n",
        "      \n",
        "    self.vocab_list=['<PAD>','<SOS>','<EOS>']+sorted(list(self.uniq_words))\n",
        "    self.num_list=[0,1,2]+self.num_list\n",
        "    print(\"Built vocabulary having {} elements\".format(len(self.vocab_list)))\n",
        "    print(\"Largest sentence length (with tags):{}\".format(self.maxlen))\n",
        "    return dict(zip(self.vocab_list,self.num_list)),dict(zip(self.num_list,self.vocab_list))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JVuh6iKohIC"
      },
      "source": [
        "#Objects of Vocab_builder class\n",
        "eng=Vocab_builder('eng',df['eng'])\n",
        "ger=Vocab_builder('ger',df['ger'])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL4ZAsYizIsd",
        "outputId": "d09d2421-a8e1-45bb-9b13-b5a9bca26d1e"
      },
      "source": [
        "#English word to index and index to word dictionaries\n",
        "eng_w2i,eng_i2w=eng.build_vocab()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built vocabulary having 3655 elements\n",
            "Largest sentence length (with tags):9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsH4pLi3zOcS",
        "outputId": "6bf78326-8ab1-452e-c323-0e214fa76f91"
      },
      "source": [
        "#checking for special characters in English dictionary\n",
        "for i in sorted (eng_w2i.keys())[:20] :  \n",
        "     print(i, end = \" \") "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! $ - . <EOS> <PAD> <SOS> ? a aah abandon abandoned abated abhor able aboard about abroad absent absurd "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWE4mEkcMF2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4609a9c-6a8f-4136-a1e2-fd570f00e53b"
      },
      "source": [
        "#German word to index and index to word dictionaries\n",
        "ger_w2i,ger_i2w=ger.build_vocab()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built vocabulary having 4892 elements\n",
            "Largest sentence length (with tags):13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDAzP_ePoJK0",
        "outputId": "6efc9698-c879-4338-ca3a-112771cbe133"
      },
      "source": [
        "#checking if the index dictionaries are correct\n",
        "'geh'==ger_i2w[ger_w2i['geh']]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tylnxt3Xoqj3",
        "outputId": "eb856ac8-6ef3-46e6-b970-7d4268501128"
      },
      "source": [
        "'go'==eng_i2w[eng_w2i['go']]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rglyUxdDxD3Z",
        "outputId": "c27fdf6e-fbc8-476a-a14f-8a81da00f913"
      },
      "source": [
        "#checking for special characters in German dictionary\n",
        "for i in sorted (ger_w2i.keys())[:20] :  \n",
        "     print(i, end = \" \") "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! $ - . <EOS> <PAD> <SOS> ? ab abbiegen abend abendbrot abendessen abenteuer aber abgefahren abgekommen abgelaufen abgelehnt abgelenkt "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HctDyjqmxKuX"
      },
      "source": [
        "def sent_to_ind(sentence,lang):\n",
        "  '''\n",
        "  Tokenizes a string and\n",
        "  converts it to an np array of \n",
        "  indices and pads the \n",
        "  array according to max sentence length\n",
        "  '''\n",
        "  ind_list=[]\n",
        "  if lang=='eng':\n",
        "    tokens=eng.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      ind_list.append(eng_w2i[token])\n",
        "    while len(ind_list)<max(ger.maxlen,eng.maxlen):\n",
        "      ind_list.append(0)\n",
        "  else:\n",
        "    tokens=ger.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      ind_list.append(ger_w2i[token])\n",
        "    while len(ind_list)<max(ger.maxlen,eng.maxlen):\n",
        "      ind_list.append(0)\n",
        "    \n",
        "  return np.array(ind_list)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix5EpSK3eQod",
        "outputId": "4aa5969f-074d-40c7-fedc-b60257f59250"
      },
      "source": [
        "#Checking correctness of sentence to index conversion\n",
        "test_lis=sent_to_ind('<SOS> tom wird bald hier sein . was hei√üt bald ? <EOS>','ger')\n",
        "\n",
        "print(len(test_lis))\n",
        "print(test_lis)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "[   1 4003 4686  309 1988 3604    6 4568 1946  309    7    2    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfhMnYBhXb8",
        "outputId": "955bf1f6-d954-4209-96c2-1bfa0e0aa13e"
      },
      "source": [
        "test_lis=sent_to_ind(\"<SOS> tom will be here soon . how soon ? <EOS>\",'eng')\n",
        "print(len(test_lis))\n",
        "print(test_lis)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "[   1 3269 3557  262 1477 2927    6 1551 2927    7    2    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VENEOHriC99"
      },
      "source": [
        "#splitting the data into training,testing and validation sets\n",
        "\n",
        "train_x,test_x,train_y,test_y=train_test_split(df['eng'],df['ger'],test_size=0.1,random_state=42)\n",
        "train_x,val_x,train_y,val_y=train_test_split(train_x,train_y,test_size=0.23,random_state=42)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NetMWl-AtVvi"
      },
      "source": [
        "def sent_to_np(series,lang,translate_mode):\n",
        "  '''\n",
        "  Converts a dataframe column to \n",
        "  a unsqueezed np array of indexes\n",
        "  with padding for feeding into NN\n",
        "  '''\n",
        "  ret_list=[]\n",
        "  if translate_mode==False :\n",
        "    if lang=='eng':\n",
        "      for index,val in series.items():\n",
        "        ret_list.append(sent_to_ind(val,'eng'))\n",
        "    else:\n",
        "      for index,val in series.items():\n",
        "        ret_list.append(sent_to_ind(val,'ger'))\n",
        "    \n",
        "    ret_list=np.array(ret_list)\n",
        "    return np.expand_dims(ret_list,axis=2)\n",
        "  else:\n",
        "    ans=sent_to_ind(series,'eng')\n",
        "    ans=np.expand_dims(ans,axis=0)\n",
        "    ans=np.expand_dims(ans,axis=2)\n",
        "    return ans\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdCHrrTaSqww"
      },
      "source": [
        "train_x=sent_to_np(train_x,'eng',False)\n",
        "train_y=sent_to_np(train_y,'ger',False)\n",
        "test_x=sent_to_np(test_x,'eng',False)\n",
        "test_y=sent_to_np(test_y,'ger',False)\n",
        "val_x=sent_to_np(val_x,'eng',False)\n",
        "val_y=sent_to_np(val_y,'ger',False)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLHAZ_vw7un7",
        "outputId": "b9d59f7a-14ba-49f5-b4e0-765bcb7b540f"
      },
      "source": [
        "#one hot encoding \r\n",
        "train_y=to_categorical(train_y,num_classes=len(ger.vocab_list))\r\n",
        "test_y=to_categorical(test_y,num_classes=len(ger.vocab_list))\r\n",
        "val_y=to_categorical(val_y,num_classes=len(ger.vocab_list))\r\n",
        "print(train_y.shape)\r\n",
        "print(test_y.shape)\r\n",
        "print(val_y.shape)\r\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10291, 13, 4892)\n",
            "(1485, 13, 4892)\n",
            "(3074, 13, 4892)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDpCjhQZur_O",
        "outputId": "07eff9f4-ab7a-4f03-c939-5541128254be"
      },
      "source": [
        "# [batch,timesteps,feature]\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10291, 13, 1)\n",
            "(10291, 13, 4892)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Frd_j1wuxz5",
        "outputId": "591001c0-a709-45b2-b085-1ee9b776a9cd"
      },
      "source": [
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1485, 13, 1)\n",
            "(1485, 13, 4892)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1dFoeFhuzjt",
        "outputId": "614f4545-2427-4e9a-91d4-7ed23403ce42"
      },
      "source": [
        "print(val_x.shape)\n",
        "print(val_y.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3074, 13, 1)\n",
            "(3074, 13, 4892)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zt6VKybF7WK"
      },
      "source": [
        "def translate(sentence,mod,embedded):\n",
        "  '''\n",
        "  Function for translating given English sentence\n",
        "  to German using model predictions\n",
        "  '''\n",
        "  ans=\"\"\n",
        "  preproc_sent=process_text(sentence,True)\n",
        "  \n",
        "  model_inp=sent_to_np(preproc_sent,'eng',True)\n",
        "  if (embedded):\n",
        "    model_inp=np.squeeze(model_inp,axis=2)\n",
        "  \n",
        "  pred=mod.predict(model_inp)\n",
        "  for i in pred[0]:\n",
        "    ind=np.argmax(i)\n",
        "    if(ger_i2w[ind]=='<SOS>' or ger_i2w[ind]=='<EOS>' or ger_i2w[ind]=='<PAD>'):\n",
        "        continue\n",
        "    ans+=ger_i2w[ind]\n",
        "    ans+=\" \"\n",
        "  return ans"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_cqENbVFpVI"
      },
      "source": [
        "#training starts here ----------------------------------------------------------"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jBADUl-Buhn",
        "outputId": "c1e68374-a724-4c7f-fb00-67954a3a72f5"
      },
      "source": [
        "\n",
        "#Removing singleton axis  3rd axis\n",
        "#for embedding layer\n",
        "t_x=np.squeeze(train_x,axis=2)\n",
        "v_x=np.squeeze(val_x,axis=2)\n",
        "te_x=np.squeeze(test_x,axis=2)\n",
        "print(t_x.shape)\n",
        "print(v_x.shape)\n",
        "print(te_x.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10291, 13)\n",
            "(3074, 13)\n",
            "(1485, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEFKmQmibP_y"
      },
      "source": [
        "\n",
        "def leaky_relu(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=0.03)\n",
        "  \n",
        "# @tf.function\n",
        "# def bleu_score(y_true,y_pred):\n",
        "#   true_ind=[]\n",
        "#   pred_ind=[]\n",
        "#   for i in y_pred[0]:\n",
        "#     ind=np.argmax(i)\n",
        "#     if(ger_i2w[ind]=='<SOS>' or ger_i2w[ind]=='<EOS>' or ger_i2w[ind]=='<PAD>'):\n",
        "#         continue\n",
        "#     pred_ind.append(ger_i2w[ind])\n",
        "#   for i in y_true[0]:\n",
        "#     ind=np.argmax(i)\n",
        "#     if(ger_i2w[ind]=='<SOS>' or ger_i2w[ind]=='<EOS>' or ger_i2w[ind]=='<PAD>'):\n",
        "#         continue\n",
        "#     true_ind.append(ger_i2w[ind])\n",
        "#   return list_bleu([true_ind],pred_ind)\n",
        "\n",
        "\n",
        "def base_LSTM_model_HP_TUNING(hp):\n",
        "  '''\n",
        "  Simple LSTM model for hyperparameter tuning\n",
        "  '''\n",
        "  m1_lstm_units=hp.Int('units',min_value=32,max_value=128,step=32)\n",
        "  m1_lr=hp.Choice('learning_rate', values = [0.001,0.003,0.005,0.008,0.01,0.05]) \n",
        "  lstm=LSTM(m1_lstm_units,return_sequences=True,activation='tanh')  #LSTM layer with output being hiddent state at time t\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation='softmax')) #Dense layer acting on hidden output at each step to generate predictions\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(InputLayer(train_x.shape[1:]))\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=categorical_crossentropy,optimizer=Adam(m1_lr),metrics=['accuracy','MeanSquaredError',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "  return model\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQohAY2OPyV8"
      },
      "source": [
        "def embedding_LSTM_HP_TUNING(hp):\n",
        "  '''\n",
        "  LSTM model with embedding layer for hyperparameter tuning\n",
        "  '''\n",
        "  m2_lstm_units=hp.Int('units',min_value=32,max_value=128,step=32)\n",
        "  m2_lr=hp.Choice('learning_rate', values = [0.001,0.003,0.005,0.008,0.01,0.05,0.08])\n",
        "  embedding_col=hp.Int('output_dim',min_value=32,max_value=160,step=32)\n",
        "  lstm=LSTM(m2_lstm_units,return_sequences=True,activation='tanh')\n",
        "  print(t_x.shape[1])\n",
        "  embed=Embedding(len(ger.vocab_list),embedding_col,input_length=t_x.shape[1])\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation=\"softmax\"))\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(embed)\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=categorical_crossentropy,optimizer=Adam(m2_lr),metrics=['accuracy','MeanSquaredError',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "  return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxxlHHvjIAjf"
      },
      "source": [
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6eCU8-iy7Ii"
      },
      "source": [
        "#Hyperparameter tuning starts here\n",
        "#Hyperparameter tuning of base model\n",
        "tuner = kt.BayesianOptimization(base_LSTM_model_HP_TUNING,\n",
        "                     objective = 'val_accuracy', \n",
        "                     num_initial_points=50,\n",
        "                     max_trials=15,\n",
        "                     directory='./',\n",
        "                     project_name='base_LSTM')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_jHXV22JtT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9356eca9-f117-470e-e2a1-bc4c6b8ec9f0"
      },
      "source": [
        "tuner.search(train_x,train_y, epochs = 25, validation_data = (val_x, val_y), callbacks = [ClearTrainingOutput()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 16 Complete [00h 02m 53s]\n",
            "val_accuracy: 0.7552497386932373\n",
            "\n",
            "Best val_accuracy So Far: 0.765637218952179\n",
            "Total elapsed time: 00h 47m 45s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRHXC9iqgFgA"
      },
      "source": [
        "best_hps1 = tuner.get_best_hyperparameters(num_trials = 1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA7iXB2uieqC",
        "outputId": "c5b350f3-0052-4ec6-9b71-ee66e7fec116"
      },
      "source": [
        "best_hps1.get('units')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaZPnvb3igA4",
        "outputId": "edf45185-7648-4e5f-e907-3f4a03fc7f3c"
      },
      "source": [
        "best_hps1.get('learning_rate')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVv7aXRFioJy",
        "outputId": "7167fc26-6179-4060-cd70-c852a4882579"
      },
      "source": [
        "tuner2 = kt.BayesianOptimization(embedding_LSTM_HP_TUNING,\n",
        "                     objective = 'val_accuracy', \n",
        "                     num_initial_points=50,\n",
        "                     max_trials=30,\n",
        "                     directory='./',\n",
        "                     project_name='embedding')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "351_XxE0wjvx",
        "outputId": "d721d465-7a63-4c7b-c307-5be934665b9f"
      },
      "source": [
        "tuner2.search(t_x,train_y, epochs = 15, validation_data = (v_x, val_y), callbacks = [ClearTrainingOutput()])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 07m 08s]\n",
            "val_accuracy: 0.8056359887123108\n",
            "\n",
            "Best val_accuracy So Far: 0.8067874908447266\n",
            "Total elapsed time: 03h 46m 53s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuFGzxbtwkzH"
      },
      "source": [
        "best_hps2 = tuner2.get_best_hyperparameters(num_trials = 1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3PWz0b9wkwx",
        "outputId": "4e28e262-02b5-46d4-cbe7-b62db5543bda"
      },
      "source": [
        "best_hps2.get('units')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdrijzI-wktw",
        "outputId": "27d76356-c513-49f8-f3d8-bae31c21bd26"
      },
      "source": [
        "best_hps2.get('learning_rate')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAwDCBOOxPbb",
        "outputId": "c50c6b2d-9153-4c12-f565-8cabdc9f7c32"
      },
      "source": [
        "best_hps2.get('output_dim')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDRqYzYqv6uX"
      },
      "source": [
        "#Making base model using best hyperparameters\n",
        "def base_LSTM_model(m1_lstm_units,m1_lr):\n",
        "  '''\n",
        "  Simple LSTM model\n",
        "  '''\n",
        "  lstm=LSTM(m1_lstm_units,return_sequences=True,activation='tanh')  #LSTM layer with output being hiddent state at time t\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation='softmax')) #Dense layer acting on hidden output at each step to generate predictions\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(InputLayer(train_x.shape[1:]))\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=categorical_crossentropy,optimizer=Adam(m1_lr),metrics=['accuracy','MeanSquaredError',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "  return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFvJdTxXw6It"
      },
      "source": [
        "#Making embedding model using hyperparameters\n",
        "def embedding_LSTM(m2_lstm_units,m2_lr,embedding_col):\n",
        "  '''\n",
        "  LSTM model with embedding layer\n",
        "  '''\n",
        "  lstm=LSTM(m2_lstm_units,return_sequences=True,activation='tanh')\n",
        "  print(t_x.shape[1])\n",
        "  embed=Embedding(len(ger.vocab_list),embedding_col,input_length=t_x.shape[1])\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation=\"softmax\"))\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(embed)\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=categorical_crossentropy,optimizer=Adam(m2_lr),metrics=['accuracy','MeanSquaredError',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "  return model"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWOrrfsRNOcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a6e1da-b841-40f3-feb6-637888121e30"
      },
      "source": [
        "base_model=base_LSTM_model(128,0.001)\n",
        "base_model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 13, 128)           66560     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 13, 4892)          631068    \n",
            "=================================================================\n",
            "Total params: 697,628\n",
            "Trainable params: 697,628\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzsf600cPN9w",
        "outputId": "04c691d6-48b9-4dad-c56f-40c7ed8039d5"
      },
      "source": [
        "#training the base model\n",
        "\n",
        "base_model.fit(train_x,train_y,m1_batch_size,m1_epochs,validation_data=(val_x,val_y))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 10291 samples, validate on 3074 samples\n",
            "Epoch 1/25\n",
            "10291/10291 [==============================] - 6s 630us/sample - loss: 4.3647 - acc: 0.5011 - mean_squared_error: 1.4518e-04 - precision: 0.8667 - recall: 0.2817 - val_loss: 2.7100 - val_acc: 0.5436 - val_mean_squared_error: 1.0363e-04 - val_precision: 0.9229 - val_recall: 0.4866\n",
            "Epoch 2/25\n",
            "10291/10291 [==============================] - 4s 417us/sample - loss: 2.6187 - acc: 0.6354 - mean_squared_error: 1.0137e-04 - precision: 0.9243 - recall: 0.4841 - val_loss: 2.5755 - val_acc: 0.6543 - val_mean_squared_error: 1.0003e-04 - val_precision: 0.9230 - val_recall: 0.4868\n",
            "Epoch 3/25\n",
            "10291/10291 [==============================] - 4s 416us/sample - loss: 2.4733 - acc: 0.6553 - mean_squared_error: 9.9661e-05 - precision: 0.9265 - recall: 0.4821 - val_loss: 2.4020 - val_acc: 0.6469 - val_mean_squared_error: 9.8912e-05 - val_precision: 0.9236 - val_recall: 0.4865\n",
            "Epoch 4/25\n",
            "10291/10291 [==============================] - 4s 412us/sample - loss: 2.2162 - acc: 0.6604 - mean_squared_error: 9.7923e-05 - precision: 0.9271 - recall: 0.4830 - val_loss: 2.0814 - val_acc: 0.6631 - val_mean_squared_error: 9.4069e-05 - val_precision: 0.9210 - val_recall: 0.4892\n",
            "Epoch 5/25\n",
            "10291/10291 [==============================] - 4s 410us/sample - loss: 1.9334 - acc: 0.6624 - mean_squared_error: 8.6584e-05 - precision: 0.9288 - recall: 0.5355 - val_loss: 1.9274 - val_acc: 0.6628 - val_mean_squared_error: 8.2672e-05 - val_precision: 0.9280 - val_recall: 0.5705\n",
            "Epoch 6/25\n",
            "10291/10291 [==============================] - 4s 412us/sample - loss: 1.8639 - acc: 0.6631 - mean_squared_error: 8.2548e-05 - precision: 0.9236 - recall: 0.5718 - val_loss: 1.9042 - val_acc: 0.6632 - val_mean_squared_error: 8.1941e-05 - val_precision: 0.9224 - val_recall: 0.5769\n",
            "Epoch 7/25\n",
            "10291/10291 [==============================] - 4s 407us/sample - loss: 1.8423 - acc: 0.6651 - mean_squared_error: 8.2114e-05 - precision: 0.9231 - recall: 0.5744 - val_loss: 1.8932 - val_acc: 0.6810 - val_mean_squared_error: 8.1711e-05 - val_precision: 0.9213 - val_recall: 0.5774\n",
            "Epoch 8/25\n",
            "10291/10291 [==============================] - 4s 415us/sample - loss: 1.8264 - acc: 0.6674 - mean_squared_error: 8.1825e-05 - precision: 0.9195 - recall: 0.5776 - val_loss: 1.8868 - val_acc: 0.6629 - val_mean_squared_error: 8.1419e-05 - val_precision: 0.8990 - val_recall: 0.5985\n",
            "Epoch 9/25\n",
            "10291/10291 [==============================] - 4s 422us/sample - loss: 1.8123 - acc: 0.6732 - mean_squared_error: 8.1588e-05 - precision: 0.9173 - recall: 0.5805 - val_loss: 1.8733 - val_acc: 0.6827 - val_mean_squared_error: 8.1034e-05 - val_precision: 0.9226 - val_recall: 0.5793\n",
            "Epoch 10/25\n",
            "10291/10291 [==============================] - 4s 430us/sample - loss: 1.7968 - acc: 0.6786 - mean_squared_error: 8.1231e-05 - precision: 0.9183 - recall: 0.5810 - val_loss: 1.8618 - val_acc: 0.6838 - val_mean_squared_error: 8.0724e-05 - val_precision: 0.9312 - val_recall: 0.5741\n",
            "Epoch 11/25\n",
            "10291/10291 [==============================] - 4s 434us/sample - loss: 1.7800 - acc: 0.6819 - mean_squared_error: 8.0831e-05 - precision: 0.9163 - recall: 0.5837 - val_loss: 1.8470 - val_acc: 0.6887 - val_mean_squared_error: 8.0248e-05 - val_precision: 0.9154 - val_recall: 0.5856\n",
            "Epoch 12/25\n",
            "10291/10291 [==============================] - 4s 420us/sample - loss: 1.7624 - acc: 0.6862 - mean_squared_error: 8.0277e-05 - precision: 0.9166 - recall: 0.5839 - val_loss: 1.8340 - val_acc: 0.6897 - val_mean_squared_error: 7.9661e-05 - val_precision: 0.9167 - val_recall: 0.5835\n",
            "Epoch 13/25\n",
            "10291/10291 [==============================] - 4s 414us/sample - loss: 1.7416 - acc: 0.6885 - mean_squared_error: 7.9682e-05 - precision: 0.9145 - recall: 0.5864 - val_loss: 1.8160 - val_acc: 0.6922 - val_mean_squared_error: 7.8994e-05 - val_precision: 0.9115 - val_recall: 0.5893\n",
            "Epoch 14/25\n",
            "10291/10291 [==============================] - 4s 428us/sample - loss: 1.7225 - acc: 0.6897 - mean_squared_error: 7.9163e-05 - precision: 0.9145 - recall: 0.5866 - val_loss: 1.8025 - val_acc: 0.6916 - val_mean_squared_error: 7.8679e-05 - val_precision: 0.9118 - val_recall: 0.5892\n",
            "Epoch 15/25\n",
            "10291/10291 [==============================] - 4s 421us/sample - loss: 1.7050 - acc: 0.6914 - mean_squared_error: 7.8733e-05 - precision: 0.9110 - recall: 0.5896 - val_loss: 1.7979 - val_acc: 0.6898 - val_mean_squared_error: 7.8497e-05 - val_precision: 0.9250 - val_recall: 0.5800\n",
            "Epoch 16/25\n",
            "10291/10291 [==============================] - 4s 413us/sample - loss: 1.6909 - acc: 0.6930 - mean_squared_error: 7.8439e-05 - precision: 0.9119 - recall: 0.5894 - val_loss: 1.7830 - val_acc: 0.6937 - val_mean_squared_error: 7.8004e-05 - val_precision: 0.9020 - val_recall: 0.6008\n",
            "Epoch 17/25\n",
            "10291/10291 [==============================] - 4s 420us/sample - loss: 1.6774 - acc: 0.6946 - mean_squared_error: 7.8147e-05 - precision: 0.9089 - recall: 0.5926 - val_loss: 1.7759 - val_acc: 0.6940 - val_mean_squared_error: 7.7876e-05 - val_precision: 0.9191 - val_recall: 0.5858\n",
            "Epoch 18/25\n",
            "10291/10291 [==============================] - 4s 416us/sample - loss: 1.6649 - acc: 0.6960 - mean_squared_error: 7.7915e-05 - precision: 0.9092 - recall: 0.5928 - val_loss: 1.7654 - val_acc: 0.6940 - val_mean_squared_error: 7.7772e-05 - val_precision: 0.9341 - val_recall: 0.5742\n",
            "Epoch 19/25\n",
            "10291/10291 [==============================] - 4s 423us/sample - loss: 1.6530 - acc: 0.6975 - mean_squared_error: 7.7679e-05 - precision: 0.9100 - recall: 0.5936 - val_loss: 1.7564 - val_acc: 0.6996 - val_mean_squared_error: 7.7286e-05 - val_precision: 0.9106 - val_recall: 0.5955\n",
            "Epoch 20/25\n",
            "10291/10291 [==============================] - 4s 413us/sample - loss: 1.6409 - acc: 0.6982 - mean_squared_error: 7.7495e-05 - precision: 0.9087 - recall: 0.5963 - val_loss: 1.7520 - val_acc: 0.6997 - val_mean_squared_error: 7.7143e-05 - val_precision: 0.9117 - val_recall: 0.5939\n",
            "Epoch 21/25\n",
            "10291/10291 [==============================] - 4s 420us/sample - loss: 1.6336 - acc: 0.6979 - mean_squared_error: 7.7477e-05 - precision: 0.9082 - recall: 0.5963 - val_loss: 1.7520 - val_acc: 0.7006 - val_mean_squared_error: 7.7310e-05 - val_precision: 0.9021 - val_recall: 0.6012\n",
            "Epoch 22/25\n",
            "10291/10291 [==============================] - 4s 418us/sample - loss: 1.6239 - acc: 0.6984 - mean_squared_error: 7.7336e-05 - precision: 0.9072 - recall: 0.5994 - val_loss: 1.7436 - val_acc: 0.7003 - val_mean_squared_error: 7.6906e-05 - val_precision: 0.9081 - val_recall: 0.6132\n",
            "Epoch 23/25\n",
            "10291/10291 [==============================] - 4s 413us/sample - loss: 1.6147 - acc: 0.6991 - mean_squared_error: 7.7147e-05 - precision: 0.9051 - recall: 0.6052 - val_loss: 1.7412 - val_acc: 0.7007 - val_mean_squared_error: 7.7013e-05 - val_precision: 0.9085 - val_recall: 0.5989\n",
            "Epoch 24/25\n",
            "10291/10291 [==============================] - 4s 425us/sample - loss: 1.6062 - acc: 0.6999 - mean_squared_error: 7.7041e-05 - precision: 0.9052 - recall: 0.6065 - val_loss: 1.7357 - val_acc: 0.7012 - val_mean_squared_error: 7.6703e-05 - val_precision: 0.8978 - val_recall: 0.6204\n",
            "Epoch 25/25\n",
            "10291/10291 [==============================] - 4s 436us/sample - loss: 1.5985 - acc: 0.6998 - mean_squared_error: 7.6949e-05 - precision: 0.9033 - recall: 0.6121 - val_loss: 1.7299 - val_acc: 0.7026 - val_mean_squared_error: 7.6595e-05 - val_precision: 0.8930 - val_recall: 0.6149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2db5384ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nDxB8O0Dr33",
        "outputId": "b27e8b72-27a8-4800-bab2-340733b745d8"
      },
      "source": [
        "#Evaluating LSTM model on unseen data\n",
        "\n",
        "l,acc,mse,p,r=base_model.evaluate(test_x,test_y)\n",
        "print(\"Base model loss for testing set:{}\".format(l))\n",
        "print(\"Base model MSE for testing set:{}\".format(mse))\n",
        "print(\"Base model accuracy for testing set:{}\".format(acc))\n",
        "print(\"Base model precision for testing set:{}\".format(p))\n",
        "print(\"Base model recall for testing set:{}\".format(r))\n",
        "print(\"Base model f1_score for testing set:{}\".format((2*p*r)/(p+r)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1485/1485 [==============================] - 1s 400us/sample - loss: 1.7264 - acc: 0.7080 - mean_squared_error: 7.6027e-05 - precision_7: 0.8947 - recall_6: 0.6224\n",
            "Base model loss for testing set:1.7263565836530743\n",
            "Base model accuracy for testing set:0.7080031037330627\n",
            "Base model precision for testing set:0.8947054743766785\n",
            "Base model recall for testing set:0.6223776340484619\n",
            "Base model f1_score for testing set:0.73409907650077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V7nQnNrM6ck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2be4360f-6157-4e3c-8c20-0c2bf7aa7bff"
      },
      "source": [
        "#Sample translation by base LSTM model\n",
        "translate(\"work here\",base_model,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tom ist ! ! '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB5CvJLV5LzC",
        "outputId": "1b2e8607-9ac9-44db-bc12-d47559b02a11"
      },
      "source": [
        "embeded_model=embedding_LSTM(96,0.01,128)\n",
        "embeded_model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 13, 96)            469632    \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 13, 128)           115200    \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 13, 4892)          631068    \n",
            "=================================================================\n",
            "Total params: 1,215,900\n",
            "Trainable params: 1,215,900\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUWKsmwb5bZB",
        "outputId": "1104a8d8-0016-403f-9ef5-b809bf546086"
      },
      "source": [
        "#training embedding model\n",
        "embeded_model.fit(t_x,train_y,batch_size=128,epochs=15,validation_data=(v_x,val_y))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10291 samples, validate on 3074 samples\n",
            "Epoch 1/15\n",
            "10291/10291 [==============================] - 6s 540us/sample - loss: 3.0307 - acc: 0.5968 - mean_squared_error: 1.0956e-04 - precision_7: 0.8333 - recall_7: 0.4982 - val_loss: 2.2306 - val_acc: 0.6865 - val_mean_squared_error: 7.8585e-05 - val_precision_7: 0.9610 - val_recall_7: 0.5674\n",
            "Epoch 2/15\n",
            "10291/10291 [==============================] - 4s 434us/sample - loss: 2.0342 - acc: 0.7146 - mean_squared_error: 7.2830e-05 - precision_7: 0.9225 - recall_7: 0.6504 - val_loss: 1.7088 - val_acc: 0.7260 - val_mean_squared_error: 6.8857e-05 - val_precision_7: 0.9119 - val_recall_7: 0.6851\n",
            "Epoch 3/15\n",
            "10291/10291 [==============================] - 5s 448us/sample - loss: 1.5261 - acc: 0.7528 - mean_squared_error: 6.3205e-05 - precision_7: 0.9270 - recall_7: 0.7043 - val_loss: 1.4857 - val_acc: 0.7531 - val_mean_squared_error: 6.3955e-05 - val_precision_7: 0.9103 - val_recall_7: 0.7078\n",
            "Epoch 4/15\n",
            "10291/10291 [==============================] - 5s 442us/sample - loss: 1.2801 - acc: 0.7829 - mean_squared_error: 5.6456e-05 - precision_7: 0.9324 - recall_7: 0.7393 - val_loss: 1.3692 - val_acc: 0.7775 - val_mean_squared_error: 5.9046e-05 - val_precision_7: 0.9163 - val_recall_7: 0.7335\n",
            "Epoch 5/15\n",
            "10291/10291 [==============================] - 5s 443us/sample - loss: 1.1132 - acc: 0.8030 - mean_squared_error: 5.2042e-05 - precision_7: 0.9360 - recall_7: 0.7612 - val_loss: 1.2899 - val_acc: 0.7920 - val_mean_squared_error: 5.6428e-05 - val_precision_7: 0.9175 - val_recall_7: 0.7470\n",
            "Epoch 6/15\n",
            "10291/10291 [==============================] - 5s 438us/sample - loss: 0.9760 - acc: 0.8198 - mean_squared_error: 4.8618e-05 - precision_7: 0.9392 - recall_7: 0.7754 - val_loss: 1.2418 - val_acc: 0.7989 - val_mean_squared_error: 5.5406e-05 - val_precision_7: 0.9124 - val_recall_7: 0.7549\n",
            "Epoch 7/15\n",
            "10291/10291 [==============================] - 5s 447us/sample - loss: 0.8594 - acc: 0.8333 - mean_squared_error: 4.5836e-05 - precision_7: 0.9409 - recall_7: 0.7878 - val_loss: 1.2105 - val_acc: 0.8043 - val_mean_squared_error: 5.4756e-05 - val_precision_7: 0.9082 - val_recall_7: 0.7621\n",
            "Epoch 8/15\n",
            "10291/10291 [==============================] - 5s 442us/sample - loss: 0.7596 - acc: 0.8461 - mean_squared_error: 4.3201e-05 - precision_7: 0.9420 - recall_7: 0.8001 - val_loss: 1.1849 - val_acc: 0.8104 - val_mean_squared_error: 5.4074e-05 - val_precision_7: 0.9078 - val_recall_7: 0.7673\n",
            "Epoch 9/15\n",
            "10291/10291 [==============================] - 4s 437us/sample - loss: 0.6769 - acc: 0.8577 - mean_squared_error: 4.0862e-05 - precision_7: 0.9426 - recall_7: 0.8105 - val_loss: 1.1727 - val_acc: 0.8128 - val_mean_squared_error: 5.3691e-05 - val_precision_7: 0.9039 - val_recall_7: 0.7721\n",
            "Epoch 10/15\n",
            "10291/10291 [==============================] - 5s 439us/sample - loss: 0.6042 - acc: 0.8697 - mean_squared_error: 3.8170e-05 - precision_7: 0.9451 - recall_7: 0.8222 - val_loss: 1.1657 - val_acc: 0.8161 - val_mean_squared_error: 5.3409e-05 - val_precision_7: 0.9000 - val_recall_7: 0.7799\n",
            "Epoch 11/15\n",
            "10291/10291 [==============================] - 5s 441us/sample - loss: 0.5466 - acc: 0.8785 - mean_squared_error: 3.6010e-05 - precision_7: 0.9456 - recall_7: 0.8314 - val_loss: 1.1626 - val_acc: 0.8178 - val_mean_squared_error: 5.2952e-05 - val_precision_7: 0.9015 - val_recall_7: 0.7821\n",
            "Epoch 12/15\n",
            "10291/10291 [==============================] - 5s 447us/sample - loss: 0.4977 - acc: 0.8886 - mean_squared_error: 3.3641e-05 - precision_7: 0.9476 - recall_7: 0.8430 - val_loss: 1.1624 - val_acc: 0.8174 - val_mean_squared_error: 5.3281e-05 - val_precision_7: 0.8957 - val_recall_7: 0.7846\n",
            "Epoch 13/15\n",
            "10291/10291 [==============================] - 5s 449us/sample - loss: 0.4563 - acc: 0.8963 - mean_squared_error: 3.1595e-05 - precision_7: 0.9492 - recall_7: 0.8528 - val_loss: 1.1650 - val_acc: 0.8184 - val_mean_squared_error: 5.3055e-05 - val_precision_7: 0.8953 - val_recall_7: 0.7886\n",
            "Epoch 14/15\n",
            "10291/10291 [==============================] - 5s 461us/sample - loss: 0.4188 - acc: 0.9037 - mean_squared_error: 2.9440e-05 - precision_7: 0.9521 - recall_7: 0.8644 - val_loss: 1.1845 - val_acc: 0.8184 - val_mean_squared_error: 5.3604e-05 - val_precision_7: 0.8926 - val_recall_7: 0.7913\n",
            "Epoch 15/15\n",
            "10291/10291 [==============================] - 5s 447us/sample - loss: 0.3893 - acc: 0.9088 - mean_squared_error: 2.7801e-05 - precision_7: 0.9528 - recall_7: 0.8731 - val_loss: 1.1894 - val_acc: 0.8175 - val_mean_squared_error: 5.3879e-05 - val_precision_7: 0.8900 - val_recall_7: 0.7915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f50bf069240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjapHrel-XV3",
        "outputId": "f306ccec-98ad-40c6-d4e4-91a353ce8a43"
      },
      "source": [
        "l,acc,mse,p,r=embeded_model.evaluate(te_x,test_y)\n",
        "print(\"Embedded model loss for testing set:{}\".format(l))\n",
        "print(\"Embedded model accuracy for testing set:{}\".format(acc))\n",
        "print(\"Embedded model MSE for testing set:{}\".format(mse))\n",
        "print(\"Embedded model precision for testing set:{}\".format(p))\n",
        "print(\"Embedded model recall for testing set:{}\".format(r))\n",
        "print(\"Embedded model f1_score for testing set:{}\".format((2*p*r)/(p+r)))\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1485/1485 [==============================] - 1s 367us/sample - loss: 1.1855 - acc: 0.8212 - mean_squared_error: 5.2995e-05 - precision_7: 0.8933 - recall_7: 0.7934\n",
            "Embedded model loss for testing set:1.1855315887566769\n",
            "Embedded model accuracy for testing set:0.8211862444877625\n",
            "Embedded model MSE for testing set:5.299515760270879e-05\n",
            "Embedded model precision for testing set:0.8932695388793945\n",
            "Embedded model recall for testing set:0.7933695912361145\n",
            "Embedded model f1_score for testing set:0.8403610485671513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS2mEhvO-0kE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1f030581-4ca2-45e5-c18e-f0612b42e03e"
      },
      "source": [
        "translate(\"I am so small\",embeded_model,True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ich bin so klein . '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRyMtkgul-z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvwRH3HrGZkf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPTRowYDGhwJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}